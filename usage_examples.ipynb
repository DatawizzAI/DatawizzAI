{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Welcome to DataWizzAI"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the functionalities of our Python package, there are a few preliminary steps you'll need to follow to set up your environment. This guide will walk you through importing required packages, loading environment variables, and initializing the language model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all the necessary packages that our application relies on. This includes utilities for loading environment variables, interfacing with OpenAI's language models, defining data structures, and consuming data.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:02:58.148888Z",
     "start_time": "2024-05-19T12:02:58.145236Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from src.DataDefiner import *\n",
    "from src.DataAugmentor import DataAugmentor\n",
    "from src.utils.utils import parse_output, try_parse_json, create_json_sample_from_csv, compose_query_message"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure these packages are installed in your Python environment. You may need to install some of them using pip if they are not already present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables are used to store configurations and sensitive information securely. Use dotenv to load these variables from a .env file in your project directory."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:02:58.479705Z",
     "start_time": "2024-05-19T12:02:58.475303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#install if you don't have this package already\n",
    "#!pip install python-dotenv\n",
    "\n",
    "#import relevant functions\n",
    "from dotenv import load_dotenv, find_dotenv"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-19T12:02:58.503675Z",
     "start_time": "2024-05-19T12:02:58.495284Z"
    }
   },
   "source": [
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize the language model from OpenAI. In this example, we're using the gpt-3.5-turbo model with a specific temperature setting. The ChatOpenAI class is a part of the langchain_openai package and facilitates interaction with OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:02:59.123993Z",
     "start_time": "2024-05-19T12:02:58.525303Z"
    }
   },
   "source": [
    "# please make sure OPENAI_API_KEY is loaded to your environment variables\n",
    "# Initialize language model\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature parameter controls the randomness of the model's responses, with higher values leading to more varied outputs. Adjust this setting according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing these steps, your environment is ready, and you can proceed with the specific functionalities of the package, such as defining data structures, generating datasets, and more."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Init HuggingFace Endpoint - OpenAI alternative "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:02:59.128243Z",
     "start_time": "2024-05-19T12:02:59.125010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ! pip install huggingface_hub\n",
    "# \n",
    "# # please make sure HUGGINGFACEHUB_API_TOKEN is loaded to your environment variables\n",
    "# from langchain_community.llms import HuggingFaceEndpoint\n",
    "# \n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# \n",
    "# llm = HuggingFaceEndpoint(repo_id=repo_id, max_new_tokens=2048)"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section outlines the various pipeline types available within the package, each designed to transform inputs into structured or unstructured data sets for different applications such as machine learning, databases, or flexible data formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DescriptionToMLDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal for users who want to generate machine learning datasets based on descriptive inputs. This pipeline interprets natural language descriptions of data requirements and structures, then produces datasets optimized for training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:05.584242Z",
     "start_time": "2024-05-19T12:02:59.128243Z"
    }
   },
   "source": [
    "#Initialize a DataStructureDefiner\n",
    "pipeline_name = get_pipeline_name('DescriptionToMLDataset')\n",
    "DataDefinerObj = DataDefiner(llm, pipeline_name = pipeline_name)\n",
    "\n",
    "#Define the required data structure and view the result structure\n",
    "# Example non-expert description\n",
    "dataStructureDescription = \"Generate a machine learning dataset for predicting suspicious AML transactions based on features like customer characteristics, transaction characteristics, location, and transactions history characteristics.\"\n",
    "\n",
    "# Generate professional specifications\n",
    "task_specifications = TaskSpecificationAugmentor.generate_specifications_from_description(llm, description = dataStructureDescription)\n",
    "\n",
    "# Print the generated specifications\n",
    "print(\"Generated Specifications:\")\n",
    "print(task_specifications)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigal\\PycharmProjects\\DatawizzAI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an analyst whose job is to conduct a deep research for a given task, and define the needed data to collect, making sure you don't miss any relevant detail, and gain a deep understanding of the data characteristics.1.  Generate the names of the columns relevant for the description of the user. Use indicative names. Assign each column its type - numerical, categorical, datetime, free text, unique identifier. 2. Revisit each column and complete these details:For numeric columns - describe its distribution, mean and std, min and max values. for numbers and datetimes define the needed format, for categorical columns detail a complete set of categories and its probabilities. For free text columns - specify the mean and std of the text length, For unique identifier columns - specify the format and regEX to follow. For Datetime columns - specify min and max values, as well as the time intervals mean and std values. 3. Important correlations to maintain or other constraints and dependencies. 4. Indicate what fields would be better to be generated by a LLM instead of by a simple code. 5. Indicate if this table is has sequential (transactional) nature. \n",
      "The task as described by the user: Generate a machine learning dataset for predicting suspicious AML transactions based on features like customer characteristics, transaction characteristics, location, and transactions history characteristics.;Please make sure you output a valid textual description, just guidance, no intro and summary are needed, and don't cut it in the middle.\n",
      "Generated Extracted Logic:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Generated Specifications:\n",
      "1. \n",
      "- Customer ID: unique identifier\n",
      "- Age: numerical\n",
      "- Gender: categorical\n",
      "- Occupation: categorical\n",
      "- Country: categorical\n",
      "- Transaction ID: unique identifier\n",
      "- Transaction Amount: numerical\n",
      "- Transaction Date: datetime\n",
      "\n",
      "2. \n",
      "- Age: distribution skewed right, mean=40, std=10, min=20, max=60\n",
      "- Gender: categories = {Male, Female}, probabilities = {0.6, 0.4}\n",
      "- Occupation: categories = {Student, Engineer, Lawyer}, probabilities = {0.4, 0.3, 0.3}\n",
      "- Country: categories = {USA, UK, Canada}, probabilities = {0.5, 0.3, 0.2}\n",
      "- Transaction Amount: distribution normal, mean=1000, std=500, min=100, max=2000\n",
      "- Transaction Date: format = YYYY-MM-DD, min=2021-01-01, max=2021-12-31, time intervals mean=1 day, std=0.5 days\n",
      "\n",
      "3. Important correlations:\n",
      "- Transaction Amount may be correlated with Occupation\n",
      "- Transaction Date may be correlated with Country\n",
      "\n",
      "4. Fields better generated by LLM:\n",
      "- Prediction of suspicious transactions based on historical data\n",
      "\n",
      "5. The table has a sequential (transactional) nature.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the textual description, aided with the expert specification, into a sample of the needed data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:21.840582Z",
     "start_time": "2024-05-19T12:03:05.585335Z"
    }
   },
   "source": [
    "dataStructureSample = DataDefinerObj.define_schema_from_description(description = dataStructureDescription, task_specifications=task_specifications)\n",
    "print(parse_output(dataStructureSample))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate an initial synthetic data sample for the described task (according to the user guidance if provided, or your knowledge otherwise).Provide a sample with 10 number of items; items can be records in a table,records that can potentially be joined in a DB schema, or the equivalent tuples in a JSON format in unstructured text.The task as described by the user: Generate a machine learning dataset for predicting suspicious AML transactions based on features like customer characteristics, transaction characteristics, location, and transactions history characteristics.;The guidance given by an expert: 1. \n",
      "- Customer ID: unique identifier\n",
      "- Age: numerical\n",
      "- Gender: categorical\n",
      "- Occupation: categorical\n",
      "- Country: categorical\n",
      "- Transaction ID: unique identifier\n",
      "- Transaction Amount: numerical\n",
      "- Transaction Date: datetime\n",
      "\n",
      "2. \n",
      "- Age: distribution skewed right, mean=40, std=10, min=20, max=60\n",
      "- Gender: categories = {Male, Female}, probabilities = {0.6, 0.4}\n",
      "- Occupation: categories = {Student, Engineer, Lawyer}, probabilities = {0.4, 0.3, 0.3}\n",
      "- Country: categories = {USA, UK, Canada}, probabilities = {0.5, 0.3, 0.2}\n",
      "- Transaction Amount: distribution normal, mean=1000, std=500, min=100, max=2000\n",
      "- Transaction Date: format = YYYY-MM-DD, min=2021-01-01, max=2021-12-31, time intervals mean=1 day, std=0.5 days\n",
      "\n",
      "3. Important correlations:\n",
      "- Transaction Amount may be correlated with Occupation\n",
      "- Transaction Date may be correlated with Country\n",
      "\n",
      "4. Fields better generated by LLM:\n",
      "- Prediction of suspicious transactions based on historical data\n",
      "\n",
      "5. The table has a sequential (transactional) nature.;Format instructions: Generate Sample synthetic records for tabular data (preferably a single flattened table) that can be used for training a well-performing ML model for the task described in the data description.                Please include any relevant attribute you can think of, as we do not want to miss any feature that the user may find useful.                Format the output as JSON with the dataset name as key.Please make sure you output a valid JSON format, and don't cut it in the middle.Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'AML_Transactions_Dataset':   Customer_ID  Age  Gender Occupation Country Transaction_ID  \\\n",
      "0    Cust_001   35    Male   Engineer     USA      Trans_001   \n",
      "1    Cust_002   45  Female     Lawyer      UK      Trans_002   \n",
      "2    Cust_003   55    Male    Student  Canada      Trans_003   \n",
      "3    Cust_004   30  Female   Engineer     USA      Trans_004   \n",
      "4    Cust_005   50    Male     Lawyer      UK      Trans_005   \n",
      "5    Cust_006   25  Female    Student  Canada      Trans_006   \n",
      "6    Cust_007   55    Male   Engineer     USA      Trans_007   \n",
      "7    Cust_008   40  Female     Lawyer      UK      Trans_008   \n",
      "8    Cust_009   20    Male    Student  Canada      Trans_009   \n",
      "9    Cust_010   60  Female   Engineer     USA      Trans_010   \n",
      "\n",
      "   Transaction_Amount Transaction_Date  \n",
      "0                1200       2021-05-23  \n",
      "1                 800       2021-09-14  \n",
      "2                1500       2021-03-07  \n",
      "3                1800       2021-11-30  \n",
      "4                 900       2021-07-02  \n",
      "5                1300       2021-04-19  \n",
      "6                1100       2021-10-10  \n",
      "7                1000       2021-08-15  \n",
      "8                1600       2021-06-25  \n",
      "9                1400       2021-12-05  }\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:21.844255Z",
     "start_time": "2024-05-19T12:03:21.840582Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DescriptionToDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this pipeline when you need to create a relational database schema and populate it with data, all derived from a natural language description. It’s perfect for quickly prototyping database designs or for users less familiar with SQL syntax."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:27.760631Z",
     "start_time": "2024-05-19T12:03:21.845267Z"
    }
   },
   "source": [
    "#Initialize a DataStructureDefiner\n",
    "pipeline_name = get_pipeline_name('DescriptionToDB')\n",
    "DataDefinerObj = DataDefiner(llm, pipeline_name = pipeline_name)\n",
    "\n",
    "#Define the required data structure and view the result structure\n",
    "dataStructureDescription = \"Create a database schema for a bookstore that includes tables for books, authors, and sales transactions.\"\n",
    "dataStructureSample = DataDefinerObj.define_schema_from_description(dataStructureDescription)\n",
    "print(parse_output(dataStructureSample))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate an initial synthetic data sample for the described task (according to the user guidance if provided, or your knowledge otherwise).Provide a sample with 10 number of items; items can be records in a table,records that can potentially be joined in a DB schema, or the equivalent tuples in a JSON format in unstructured text.The task as described by the user: Create a database schema for a bookstore that includes tables for books, authors, and sales transactions.;The guidance given by an expert: None;Format instructions: Generate Sample synthetic records for relational DB (one or more tables).                Please follow any relevant distributions for the stated fields, as we want this data to be as valid and useful as possible for development and testing.                Format the output as JSON with each table name as key and in the nested level the feature names as keys.Please make sure you output a valid JSON format, and don't cut it in the middle.Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'books':    book_id                                  title    genre  author_id\n",
      "0        1                       The Great Gatsby  Fiction          1\n",
      "1        2                  To Kill a Mockingbird  Classic          2\n",
      "2        3  Harry Potter and the Sorcerer's Stone  Fantasy          3, 'authors':    author_id                 name  birth_year\n",
      "0          1  F. Scott Fitzgerald        1896\n",
      "1          2           Harper Lee        1926\n",
      "2          3         J.K. Rowling        1965, 'sales_transactions':    transaction_id  book_id  quantity transaction_date\n",
      "0               1        1         2       2022-01-15\n",
      "1               2        3         1       2022-02-03\n",
      "2               3        2         3       2022-03-20}\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SQLToTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline is designed for users who prefer to define their data structure using SQL syntax. It takes SQL table creation statements and query specifications, then generates a corresponding structured, relational database schema."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:35.929027Z",
     "start_time": "2024-05-19T12:03:27.760631Z"
    }
   },
   "source": [
    "#Initialize a DataStructureDefiner\n",
    "pipeline_name = get_pipeline_name('SQLToTabular')\n",
    "DataDefinerObj = DataDefiner(llm, pipeline_name = pipeline_name)\n",
    "\n",
    "#Define the required data structure and view the result structure\n",
    "dataStructureDescription = \"-- Create a 'Customers' table with customer information\\\n",
    "CREATE TABLE Customers (\\\n",
    "    CustomerID INT PRIMARY KEY,\\\n",
    "    FirstName VARCHAR(50),\\\n",
    "    LastName VARCHAR(50),\\\n",
    "    Email VARCHAR(100),\\\n",
    "    JoinDate DATE\\\n",
    ");\\\n",
    "\\\n",
    "-- Create an 'Orders' table with order details\\\n",
    "CREATE TABLE Orders (\\\n",
    "    OrderID INT PRIMARY KEY,\\\n",
    "    CustomerID INT,\\\n",
    "    OrderDate DATE,\\\n",
    "    ProductCategory VARCHAR(50),\\\n",
    "    ProductName VARCHAR(100),\\\n",
    "    Units INT,\\\n",
    "    TotalAmount DECIMAL(10, 2),\\\n",
    "    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\\\n",
    ");\"\n",
    "dataStructureSample = DataDefinerObj.define_schema_from_description(dataStructureDescription)\n",
    "print(parse_output(dataStructureSample))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate an initial synthetic data sample for the described task (according to the user guidance if provided, or your knowledge otherwise).Provide a sample with 10 number of items; items can be records in a table,records that can potentially be joined in a DB schema, or the equivalent tuples in a JSON format in unstructured text.The task as described by the user: -- Create a 'Customers' table with customer informationCREATE TABLE Customers (    CustomerID INT PRIMARY KEY,    FirstName VARCHAR(50),    LastName VARCHAR(50),    Email VARCHAR(100),    JoinDate DATE);-- Create an 'Orders' table with order detailsCREATE TABLE Orders (    OrderID INT PRIMARY KEY,    CustomerID INT,    OrderDate DATE,    ProductCategory VARCHAR(50),    ProductName VARCHAR(100),    Units INT,    TotalAmount DECIMAL(10, 2),    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID));;The guidance given by an expert: None;Format instructions: Generate Sample synthetic data that fit to the structure given by the SQL command that appears in the data description.                Please follow any relevant distributions for the stated fields, as we want this data to be as valid and useful as possible for development and testing.                Format the output as JSON with each table name as key.Please make sure you output a valid JSON format, and don't cut it in the middle.Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'Customers':    CustomerID FirstName LastName                    Email    JoinDate\n",
      "0           1      John      Doe      johndoe@example.com  2022-01-01\n",
      "1           2      Jane    Smith    janesmith@example.com  2022-01-15\n",
      "2           3      Mike  Johnson  mikejohnson@example.com  2022-02-10\n",
      "3           4     Sarah    Brown   sarahbrown@example.com  2022-02-20, 'Orders':    OrderID  CustomerID   OrderDate ProductCategory ProductName  Units  \\\n",
      "0        1           1  2022-02-05     Electronics      Laptop      1   \n",
      "1        2           2  2022-02-10        Clothing     T-shirt      3   \n",
      "2        3           3  2022-02-15           Books       Novel      2   \n",
      "3        4           4  2022-02-20      Home Goods    Curtains      5   \n",
      "\n",
      "   TotalAmount  \n",
      "0       1200.0  \n",
      "1         60.0  \n",
      "2         25.0  \n",
      "3        100.0  }\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DescriptionToUnstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose this pipeline for scenarios where structured data formats are not required. It enables the creation of datasets with flexible formats, such as text blobs, documents, or other forms of unstructured data, based on descriptive inputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:03:45.238025Z",
     "start_time": "2024-05-19T12:03:35.929027Z"
    }
   },
   "source": [
    "#Initialize a DataStructureDefiner\n",
    "pipeline_name = get_pipeline_name('DescriptionToUnstructured')\n",
    "DataDefinerObj = DataDefiner(llm, pipeline_name = pipeline_name)\n",
    "\n",
    "#Define the required data structure and view the result structure\n",
    "dataStructureDescription = \"Generate a collection of news articles about recent technological advancements in renewable energy.\"\n",
    "dataStructureSample = DataDefinerObj.define_schema_from_description(dataStructureDescription)\n",
    "print(parse_output(dataStructureSample))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate an initial synthetic data sample for the described task (according to the user guidance if provided, or your knowledge otherwise).Provide a sample with 10 number of items; items can be records in a table,records that can potentially be joined in a DB schema, or the equivalent tuples in a JSON format in unstructured text.The task as described by the user: Generate a collection of news articles about recent technological advancements in renewable energy.;The guidance given by an expert: None;Format instructions: Generate Sample data, potentially unstructured, that fit to the data description.                Format the output as JSONL with the dataset name as key and each line contains a single sampled text in the appropriate format.Please make sure you output a valid JSON format, and don't cut it in the middle.Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'news_articles_renewable_energy':                                                title        date  \\\n",
      "0  New Solar Panel Design Increases Efficiency by...  2021-09-15   \n",
      "1  Breakthrough in Wind Turbine Technology Allows...  2021-09-17   \n",
      "2  Innovative Battery Storage Solutions Pave the ...  2021-09-20   \n",
      "3  New Geothermal Energy Extraction Method Shows ...  2021-09-22   \n",
      "4  Advancements in Wave Energy Technology Offer N...  2021-09-25   \n",
      "5  Smart Grid Technology Integration Improves Eff...  2021-09-28   \n",
      "6  Hybrid Solar-Wind Farms Show Potential for Inc...  2021-10-01   \n",
      "7  Bioenergy Breakthrough: Researchers Develop Ne...  2021-10-05   \n",
      "8  Advancements in Energy Storage Technologies En...  2021-10-08   \n",
      "9  Solar Energy Innovation: New Thin-Film Solar C...  2021-10-10   \n",
      "\n",
      "                                         description  \n",
      "0  Scientists have developed a new solar panel de...  \n",
      "1  Researchers have made a breakthrough in wind t...  \n",
      "2  Innovative battery storage solutions are pavin...  \n",
      "3  A new geothermal energy extraction method show...  \n",
      "4  Recent advancements in wave energy technology ...  \n",
      "5  Integration of smart grid technology improves ...  \n",
      "6  Hybrid solar-wind farms show potential for inc...  \n",
      "7  Researchers have made a bioenergy breakthrough...  \n",
      "8  Recent advancements in energy storage technolo...  \n",
      "9  Solar energy innovation is on the rise with ne...  }\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. APINameToData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize this pipeline when you have an API specification (e.g., OpenAPI/Swagger) and want to generate data that conforms to the defined endpoints and data models. It’s ideal for testing API endpoints or generating mock data for API development."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:04.669489Z",
     "start_time": "2024-05-19T12:03:45.238025Z"
    }
   },
   "source": [
    "#Initialize a DataStructureDefiner\n",
    "pipeline_name = get_pipeline_name('APISpecificationToData')\n",
    "DataDefinerObj = DataDefiner(llm, pipeline_name = pipeline_name)\n",
    "\n",
    "#Define the required data structure and view the result structure\n",
    "dataStructureDescription = \"Generate mock data conforming to Twitter's API. The data should include user profiles and tweets, along with metadata for engagements (likes, retweets, replies).\"\n",
    "task_specifications = TaskSpecificationAugmentor.generate_specifications_from_description(llm, description = dataStructureDescription)\n",
    "\n",
    "dataStructureSample = DataDefinerObj.define_schema_from_description(dataStructureDescription, task_specifications=task_specifications)\n",
    "print(parse_output(dataStructureSample))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an analyst whose job is to conduct a deep research for a given task, and define the needed data to collect, making sure you don't miss any relevant detail, and gain a deep understanding of the data characteristics.1.  Generate the names of the columns relevant for the description of the user. Use indicative names. Assign each column its type - numerical, categorical, datetime, free text, unique identifier. 2. Revisit each column and complete these details:For numeric columns - describe its distribution, mean and std, min and max values. for numbers and datetimes define the needed format, for categorical columns detail a complete set of categories and its probabilities. For free text columns - specify the mean and std of the text length, For unique identifier columns - specify the format and regEX to follow. For Datetime columns - specify min and max values, as well as the time intervals mean and std values. 3. Important correlations to maintain or other constraints and dependencies. 4. Indicate what fields would be better to be generated by a LLM instead of by a simple code. 5. Indicate if this table is has sequential (transactional) nature. \n",
      "The task as described by the user: Generate mock data conforming to Twitter's API. The data should include user profiles and tweets, along with metadata for engagements (likes, retweets, replies).;Please make sure you output a valid textual description, just guidance, no intro and summary are needed, and don't cut it in the middle.\n",
      "Generated Extracted Logic:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate an initial synthetic data sample for the described task (according to the user guidance if provided, or your knowledge otherwise).Provide a sample with 10 number of items; items can be records in a table,records that can potentially be joined in a DB schema, or the equivalent tuples in a JSON format in unstructured text.The task as described by the user: Generate mock data conforming to Twitter's API. The data should include user profiles and tweets, along with metadata for engagements (likes, retweets, replies).;The guidance given by an expert: 1. User Profile Data:\n",
      "   - User_ID: unique identifier\n",
      "   - Username: free text\n",
      "   - Followers_Count: numerical\n",
      "   - Following_Count: numerical\n",
      "   - Tweet_Count: numerical\n",
      "   - Created_At: datetime\n",
      "\n",
      "2. Tweet Data:\n",
      "   - Tweet_ID: unique identifier\n",
      "   - User_ID: unique identifier\n",
      "   - Tweet_Text: free text\n",
      "   - Tweet_Created_At: datetime\n",
      "   - Likes_Count: numerical\n",
      "   - Retweets_Count: numerical\n",
      "   - Replies_Count: numerical\n",
      "\n",
      "3. Engagements Data:\n",
      "   - Tweet_ID: unique identifier\n",
      "   - User_ID: unique identifier\n",
      "   - Engaged_User_ID: unique identifier\n",
      "   - Engaged_At: datetime\n",
      "   - Engagement_Type: categorical (Like, Retweet, Reply)\n",
      "\n",
      "4. Numeric columns:\n",
      "   - Followers_Count: mean=500, std=200, min=100, max=1000\n",
      "   - Following_Count: mean=300, std=150, min=50, max=700\n",
      "   - Tweet_Count: mean=100, std=50, min=20, max=200\n",
      "   - Likes_Count: mean=50, std=20, min=10, max=100\n",
      "   - Retweets_Count: mean=30, std=10, min=5, max=60\n",
      "   - Replies_Count: mean=20, std=8, min=5, max=40\n",
      "\n",
      "5. Categorical columns:\n",
      "   - Engagement_Type: {Like: 0.5, Retweet: 0.3, Reply: 0.2}\n",
      "\n",
      "6. Free text columns:\n",
      "   - Username: mean length=8, std length=2\n",
      "   - Tweet_Text: mean length=50, std length=10\n",
      "\n",
      "7. Unique identifier columns:\n",
      "   - User_ID: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Tweet_ID: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Datetime columns:\n",
      "   - Created_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "   - Tweet_Created_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "   - Engaged_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "\n",
      "9. This table is transactional in nature as it tracks the interactions between users and tweets, such as likes, retweets, and replies.;Format instructions: Check the input and output of the API that is mentioned in the user desription, and generate synthetic API calls (with valid input and output) that fit to the required structure of this API.                Format your output as JSONL, with the actual API name as key and each line containing the input and output of a synthetic API call.Please make sure you output a valid JSON format, and don't cut it in the middle.Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'twitter_api':                           input.User_ID input.Username  input.Followers_Count  \\\n",
      "0  0987ab12-3456-cdef-7890-123456789abc        user123                  450.0   \n",
      "1  0987ab12-3456-cdef-7890-123456789abc            NaN                    NaN   \n",
      "2  2345bc67-8901-def2-3456-789012345abc            NaN                    NaN   \n",
      "\n",
      "   input.Following_Count  input.Tweet_Count     input.Created_At  \\\n",
      "0                  250.0               90.0  2020-05-15 08:30:45   \n",
      "1                    NaN                NaN                  NaN   \n",
      "2                    NaN                NaN                  NaN   \n",
      "\n",
      "                       output.status                        input.Tweet_ID  \\\n",
      "0  User profile created successfully                                   NaN   \n",
      "1          Tweet posted successfully  1234cd56-7890-ab12-cdef-34567890abcd   \n",
      "2   Engagement recorded successfully  5678ef90-1234-ab56-cdef-789012345678   \n",
      "\n",
      "  input.Tweet_Text input.Tweet_Created_At  input.Likes_Count  \\\n",
      "0              NaN                    NaN                NaN   \n",
      "1     Hello world!    2021-02-20 15:10:30               70.0   \n",
      "2              NaN                    NaN                NaN   \n",
      "\n",
      "   input.Retweets_Count  input.Replies_Count  \\\n",
      "0                   NaN                  NaN   \n",
      "1                  40.0                 25.0   \n",
      "2                   NaN                  NaN   \n",
      "\n",
      "                  input.Engaged_User_ID     input.Engaged_At  \\\n",
      "0                                   NaN                  NaN   \n",
      "1                                   NaN                  NaN   \n",
      "2  0987ab12-3456-cdef-7890-123456789abc  2021-03-10 12:45:20   \n",
      "\n",
      "  input.Engagement_Type  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                  Like  }\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quering the Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up your data structure, the next step is to generate the data by refining content according to your specific needs and generating a data preview. This section guides you through the process of specifying content refinements such as region and language, initializing the data generator, and generating the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a DataAugmentor object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initialize the DataAugmentor object with your chosen language model (llm) and the predefined data structure (dataStructureSample), and with the specification for the defined data structure:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:04.675600Z",
     "start_time": "2024-05-19T12:04:04.672008Z"
    }
   },
   "source": [
    "# Content refinements\n",
    "region = 'France'\n",
    "language = 'French'\n",
    "query = \"\" "
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:19.158224Z",
     "start_time": "2024-05-19T12:04:04.675600Z"
    }
   },
   "source": [
    "# Revisiting expert specifications to adjust it to the user query\n",
    "full_query = compose_query_message(query = query, region=region, language=language)\n",
    "updated_task_specifications = TaskSpecificationAugmentor.refine_specifications_by_description(llm=llm,\n",
    "                                                                                           description=full_query, previous_task_specification = task_specifications)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an analyst whose job is to conduct a deep research for a given task, and define the needed data to collect, making sure you don't miss any relevant detail, and gain a deep understanding of the data characteristics.You already gave instructions for the needed data (see Previous Task Specifications), but now the user asks a content refinement (see User Query). Please revisit the columns distributions, and descriptive statistics and update those that have changed due to the user query. \n",
      "The User Query: Data description:  ; The required region: France ; All texts should be translated to French language.;\n",
      "Your Previous Task Specifications: 1. User Profile Data:\n",
      "   - User_ID: unique identifier\n",
      "   - Username: free text\n",
      "   - Followers_Count: numerical\n",
      "   - Following_Count: numerical\n",
      "   - Tweet_Count: numerical\n",
      "   - Created_At: datetime\n",
      "\n",
      "2. Tweet Data:\n",
      "   - Tweet_ID: unique identifier\n",
      "   - User_ID: unique identifier\n",
      "   - Tweet_Text: free text\n",
      "   - Tweet_Created_At: datetime\n",
      "   - Likes_Count: numerical\n",
      "   - Retweets_Count: numerical\n",
      "   - Replies_Count: numerical\n",
      "\n",
      "3. Engagements Data:\n",
      "   - Tweet_ID: unique identifier\n",
      "   - User_ID: unique identifier\n",
      "   - Engaged_User_ID: unique identifier\n",
      "   - Engaged_At: datetime\n",
      "   - Engagement_Type: categorical (Like, Retweet, Reply)\n",
      "\n",
      "4. Numeric columns:\n",
      "   - Followers_Count: mean=500, std=200, min=100, max=1000\n",
      "   - Following_Count: mean=300, std=150, min=50, max=700\n",
      "   - Tweet_Count: mean=100, std=50, min=20, max=200\n",
      "   - Likes_Count: mean=50, std=20, min=10, max=100\n",
      "   - Retweets_Count: mean=30, std=10, min=5, max=60\n",
      "   - Replies_Count: mean=20, std=8, min=5, max=40\n",
      "\n",
      "5. Categorical columns:\n",
      "   - Engagement_Type: {Like: 0.5, Retweet: 0.3, Reply: 0.2}\n",
      "\n",
      "6. Free text columns:\n",
      "   - Username: mean length=8, std length=2\n",
      "   - Tweet_Text: mean length=50, std length=10\n",
      "\n",
      "7. Unique identifier columns:\n",
      "   - User_ID: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Tweet_ID: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Datetime columns:\n",
      "   - Created_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "   - Tweet_Created_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "   - Engaged_At: format=YYYY-MM-DD HH:MM:SS, min value=2019-01-01 00:00:00, max value=2022-01-01 00:00:00\n",
      "\n",
      "9. This table is transactional in nature as it tracks the interactions between users and tweets, such as likes, retweets, and replies.;Please make sure you output a valid textual description, just guidance, no intro and summary are needed, and don't cut it in the middle.\n",
      "Generated Extracted Logic:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:19.163474Z",
     "start_time": "2024-05-19T12:04:19.158224Z"
    }
   },
   "source": [
    "# Initialize DataConsumer\n",
    "DataAugmentorObj = DataAugmentor(llm=llm, structure=dataStructureSample)"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a preview of your dataset to ensure it meets your requirements. You can optionally provide a query to further guide the content of the generated data. The region and language refinements will be applied to this data."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:26.999020Z",
     "start_time": "2024-05-19T12:04:19.164991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data generation that considers the expert task specification as well:\n",
    "generated_data = DataAugmentorObj.preview_output_sample(query=query, region=region, language=language, task_specifications=updated_task_specifications)\n",
    "print(generated_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description:  ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): unknown.Add Randomness: 0.1733090971346808.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'twitter_api':                           input.User_ID  input.Username  \\\n",
      "0  b177a490-7d97-4e1f-b931-06f19bbadc7e  utilisateur456   \n",
      "1  b177a490-7d97-4e1f-b931-06f19bbadc7e             NaN   \n",
      "2  6f7ef6ba-5267-4bc5-80c7-12fa578be477             NaN   \n",
      "\n",
      "   input.Followers_Count  input.Following_Count  input.Tweet_Count  \\\n",
      "0                  659.0                  412.0              130.0   \n",
      "1                    NaN                    NaN                NaN   \n",
      "2                    NaN                    NaN                NaN   \n",
      "\n",
      "      input.Created_At                        output.status  \\\n",
      "0  2019-12-10 11:25:33  Profil utilisateur créé avec succès   \n",
      "1                  NaN             Tweet publié avec succès   \n",
      "2                  NaN    Engagement enregistré avec succès   \n",
      "\n",
      "                         input.Tweet_ID        input.Tweet_Text  \\\n",
      "0                                   NaN                     NaN   \n",
      "1  e6d30d4f-b870-4a44-af52-1bc3f06baf1d  Bonjour tout le monde!   \n",
      "2  f85cc0c7-9eff-4c8d-80a4-d77433af74c2                     NaN   \n",
      "\n",
      "  input.Tweet_Created_At  input.Likes_Count  input.Retweets_Count  \\\n",
      "0                    NaN                NaN                   NaN   \n",
      "1    2020-08-28 17:45:10               85.0                  52.0   \n",
      "2                    NaN                NaN                   NaN   \n",
      "\n",
      "   input.Replies_Count                 input.Engaged_User_ID  \\\n",
      "0                  NaN                                   NaN   \n",
      "1                 27.0                                   NaN   \n",
      "2                  NaN  b177a490-7d97-4e1f-b931-06f19bbadc7e   \n",
      "\n",
      "      input.Engaged_At input.Engagement_Type  \n",
      "0                  NaN                   NaN  \n",
      "1                  NaN                   NaN  \n",
      "2  2021-06-05 09:20:15               Retweet  }\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:34.290215Z",
     "start_time": "2024-05-19T12:04:26.999020Z"
    }
   },
   "source": [
    "# Data generation that based on the user query and no additional specifications:\n",
    "generated_data = DataAugmentorObj.preview_output_sample(query=query, region=region, language=language)\n",
    "print(generated_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description:  ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"b177a490-7d97-4e1f-b931-06f19bbadc7e\",\n",
      "                \"Username\": \"utilisateur456\",\n",
      "                \"Followers_Count\": 659,\n",
      "                \"Following_Count\": 412,\n",
      "                \"Tweet_Count\": 130,\n",
      "                \"Created_At\": \"2019-12-10 11:25:33\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"e6d30d4f-b870-4a44-af52-1bc3f06baf1d\",\n",
      "                \"User_ID\": \"b177a490-7d97-4e1f-b931-06f19bbadc7e\",\n",
      "                \"Tweet_Text\": \"Bonjour tout le monde!\",\n",
      "                \"Tweet_Created_At\": \"2020-08-28 17:45:10\",\n",
      "                \"Likes_Count\": 85,\n",
      "                \"Retweets_Count\": 52,\n",
      "                \"Replies_Count\": 27\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"f85cc0c7-9eff-4c8d-80a4-d77433af74c2\",\n",
      "                \"User_ID\": \"6f7ef6ba-5267-4bc5-80c7-12fa578be477\",\n",
      "                \"Engaged_User_ID\": \"b177a490-7d97-4e1f-b931-06f19bbadc7e\",\n",
      "                \"Engaged_At\": \"2021-06-05 09:20:15\",\n",
      "                \"Engagement_Type\": \"Retweet\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.9350199425753499.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'twitter_api':                           input.User_ID  input.Username  \\\n",
      "0  c69f70dc-1716-4752-b855-899e2af6c3dd  utilisateur789   \n",
      "1  c69f70dc-1716-4752-b855-899e2af6c3dd             NaN   \n",
      "2  9c591b0d-22f8-4c29-bde6-7f52c9dab40d             NaN   \n",
      "\n",
      "   input.Followers_Count  input.Following_Count  input.Tweet_Count  \\\n",
      "0                  512.0                  301.0              105.0   \n",
      "1                    NaN                    NaN                NaN   \n",
      "2                    NaN                    NaN                NaN   \n",
      "\n",
      "      input.Created_At                        output.status  \\\n",
      "0  2020-11-20 09:35:17  Profil utilisateur créé avec succès   \n",
      "1                  NaN             Tweet publié avec succès   \n",
      "2                  NaN    Engagement enregistré avec succès   \n",
      "\n",
      "                         input.Tweet_ID input.Tweet_Text  \\\n",
      "0                                   NaN              NaN   \n",
      "1  11d6a20e-7d93-4d12-9c87-3f274ea67f3e  Bonsoir à tous!   \n",
      "2  ed0868f4-3cf5-4e1c-9b6a-77fd8ad1d6c9              NaN   \n",
      "\n",
      "  input.Tweet_Created_At  input.Likes_Count  input.Retweets_Count  \\\n",
      "0                    NaN                NaN                   NaN   \n",
      "1    2021-03-15 20:05:40               93.0                  65.0   \n",
      "2                    NaN                NaN                   NaN   \n",
      "\n",
      "   input.Replies_Count                 input.Engaged_User_ID  \\\n",
      "0                  NaN                                   NaN   \n",
      "1                 30.0                                   NaN   \n",
      "2                  NaN  c69f70dc-1716-4752-b855-899e2af6c3dd   \n",
      "\n",
      "      input.Engaged_At input.Engagement_Type  \n",
      "0                  NaN                   NaN  \n",
      "1                  NaN                   NaN  \n",
      "2  2021-07-20 11:50:25               Réponse  }\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:04:41.765486Z",
     "start_time": "2024-05-19T12:04:34.290215Z"
    }
   },
   "cell_type": "code",
   "source": "generated_data = DataAugmentorObj.preview_output_sample(query=query, region=region, language=language, task_specifications=updated_task_specifications)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description:  ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"c69f70dc-1716-4752-b855-899e2af6c3dd\",\n",
      "                \"Username\": \"utilisateur789\",\n",
      "                \"Followers_Count\": 512,\n",
      "                \"Following_Count\": 301,\n",
      "                \"Tweet_Count\": 105,\n",
      "                \"Created_At\": \"2020-11-20 09:35:17\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"11d6a20e-7d93-4d12-9c87-3f274ea67f3e\",\n",
      "                \"User_ID\": \"c69f70dc-1716-4752-b855-899e2af6c3dd\",\n",
      "                \"Tweet_Text\": \"Bonsoir à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-03-15 20:05:40\",\n",
      "                \"Likes_Count\": 93,\n",
      "                \"Retweets_Count\": 65,\n",
      "                \"Replies_Count\": 30\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"ed0868f4-3cf5-4e1c-9b6a-77fd8ad1d6c9\",\n",
      "                \"User_ID\": \"9c591b0d-22f8-4c29-bde6-7f52c9dab40d\",\n",
      "                \"Engaged_User_ID\": \"c69f70dc-1716-4752-b855-899e2af6c3dd\",\n",
      "                \"Engaged_At\": \"2021-07-20 11:50:25\",\n",
      "                \"Engagement_Type\": \"Réponse\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.8210321300620843.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Full Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the full dataset, use the consumeData method. Specify your query (if any), optionaly the region and language, and the number of records you wish to generate. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:17.350006Z",
     "start_time": "2024-05-19T12:04:41.765486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Without expert specifications\n",
    "query = \"Taylor Swift fans\"\n",
    "generated_data = DataAugmentorObj.generate_data( query=query, region=region, language=language, num_records=15) "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"a71e509e-e30b-40e7-9d1d-11e4b9174c5d\",\n",
      "                \"Username\": \"utilisateur567\",\n",
      "                \"Followers_Count\": 490,\n",
      "                \"Following_Count\": 280,\n",
      "                \"Tweet_Count\": 85,\n",
      "                \"Created_At\": \"2021-04-25 14:20:55\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"d9fc23ae-3d91-4087-95f9-02c863f3e10d\",\n",
      "                \"User_ID\": \"a71e509e-e30b-40e7-9d1d-11e4b9174c5d\",\n",
      "                \"Tweet_Text\": \"Bonne journée à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-08-10 10:45:30\",\n",
      "                \"Likes_Count\": 60,\n",
      "                \"Retweets_Count\": 35,\n",
      "                \"Replies_Count\": 18\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1604c3b0-b14c-4979-8802-8d2b8c7a4e5f\",\n",
      "                \"User_ID\": \"0843df36-1f4b-4023-8b76-fb845ec1e22a\",\n",
      "                \"Engaged_User_ID\": \"a71e509e-e30b-40e7-9d1d-11e4b9174c5d\",\n",
      "                \"Engaged_At\": \"2021-05-30 08:15:20\",\n",
      "                \"Engagement_Type\": \"Retweet\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.9502381449575543.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"b52c6e1f-41d8-4aaf-9e48-80b49b2457ba\",\n",
      "                \"Username\": \"fan123\",\n",
      "                \"Followers_Count\": 510,\n",
      "                \"Following_Count\": 300,\n",
      "                \"Tweet_Count\": 95,\n",
      "                \"Created_At\": \"2021-09-18 09:55:40\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"f8bb57c4-0cb5-471f-92c0-1d1936d9e442\",\n",
      "                \"User_ID\": \"b52c6e1f-41d8-4aaf-9e48-80b49b2457ba\",\n",
      "                \"Tweet_Text\": \"Bonjour à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-10-30 11:20:30\",\n",
      "                \"Likes_Count\": 80,\n",
      "                \"Retweets_Count\": 45,\n",
      "                \"Replies_Count\": 20\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"9a15b0d7-7b3b-4c3c-a91c-8301950f287b\",\n",
      "                \"User_ID\": \"63a8a6d4-6fb5-49b5-b796-a8255ebea3ac\",\n",
      "                \"Engaged_User_ID\": \"b52c6e1f-41d8-4aaf-9e48-80b49b2457ba\",\n",
      "                \"Engaged_At\": \"2021-12-05 16:30:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.4251289727475762.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"6097ab12-3456-cdef-1234-567890abc\",\n",
      "                \"Username\": \"fan456\",\n",
      "                \"Followers_Count\": 480,\n",
      "                \"Following_Count\": 270,\n",
      "                \"Tweet_Count\": 85,\n",
      "                \"Created_At\": \"2022-01-28 10:45:50\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"3456cd78-9012-ef34-ab56-789012345def\",\n",
      "                \"User_ID\": \"6097ab12-3456-cdef-1234-567890abc\",\n",
      "                \"Tweet_Text\": \"Salut tout le monde!\",\n",
      "                \"Tweet_Created_At\": \"2022-03-15 14:30:40\",\n",
      "                \"Likes_Count\": 75,\n",
      "                \"Retweets_Count\": 50,\n",
      "                \"Replies_Count\": 30\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"7890ef12-3456-ab78-cdef-901234567ghi\",\n",
      "                \"User_ID\": \"1234cd56-7890-ef12-ab34-56789012def\",\n",
      "                \"Engaged_User_ID\": \"6097ab12-3456-cdef-1234-567890abc\",\n",
      "                \"Engaged_At\": \"2022-05-20 17:55:10\",\n",
      "                \"Engagement_Type\": \"Retweet\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.8081904879219481.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"2345ef67-8901-cdef-1234-567890abcdef\",\n",
      "                \"Username\": \"swiftie123\",\n",
      "                \"Followers_Count\": 410,\n",
      "                \"Following_Count\": 220,\n",
      "                \"Tweet_Count\": 95,\n",
      "                \"Created_At\": \"2021-08-12 09:25:35\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"9012ab34-cdef-5678-ef90-123456789abc\",\n",
      "                \"User_ID\": \"2345ef67-8901-cdef-1234-567890abcdef\",\n",
      "                \"Tweet_Text\": \"Salut à tous!\",\n",
      "                \"Tweet_Created_At\": \"2022-04-25 08:50:15\",\n",
      "                \"Likes_Count\": 65,\n",
      "                \"Retweets_Count\": 45,\n",
      "                \"Replies_Count\": 20\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678cd90-1234-ef56-ab78-901234567def\",\n",
      "                \"User_ID\": \"3456ab78-cdef-9012-3456-789012345ghi\",\n",
      "                \"Engaged_User_ID\": \"2345ef67-8901-cdef-1234-567890abcdef\",\n",
      "                \"Engaged_At\": \"2022-07-30 18:35:25\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.011569318966963338.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language..Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"5432gh98-7654-fghe-4321-987654321hij\",\n",
      "                \"Username\": \"fan123\",\n",
      "                \"Followers_Count\": 480,\n",
      "                \"Following_Count\": 270,\n",
      "                \"Tweet_Count\": 85,\n",
      "                \"Created_At\": \"2020-10-25 11:45:30\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"3456gh12-7890-cdef-ab34-567890123def\",\n",
      "                \"User_ID\": \"5432gh98-7654-fghe-4321-987654321hij\",\n",
      "                \"Tweet_Text\": \"Bonjour à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-07-15 18:20:35\",\n",
      "                \"Likes_Count\": 75,\n",
      "                \"Retweets_Count\": 50,\n",
      "                \"Replies_Count\": 30\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"9012ij34-5678-klmn-9012-345678901jkl\",\n",
      "                \"User_ID\": \"4567kl89-mnop-qrst-1234-567890123mno\",\n",
      "                \"Engaged_User_ID\": \"5432gh98-7654-fghe-4321-987654321hij\",\n",
      "                \"Engaged_At\": \"2021-11-05 10:55:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.03196719102471213.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:50.907400Z",
     "start_time": "2024-05-19T12:05:17.350006Z"
    }
   },
   "source": [
    "# With expert specifications\n",
    "query = \"Taylor Swift fans\"\n",
    "generated_data = DataAugmentorObj.generate_data( query=query, region=region, language=language, task_specifications=updated_task_specifications, num_records=15) "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"7654fghe-4321-9876-hijk-543210987bca\",\n",
      "                \"Username\": \"fan456\",\n",
      "                \"Followers_Count\": 510,\n",
      "                \"Following_Count\": 290,\n",
      "                \"Tweet_Count\": 80,\n",
      "                \"Created_At\": \"2020-12-08 09:20:50\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"6789mn01-2345-opqr-bcde-678901234mno\",\n",
      "                \"User_ID\": \"7654fghe-4321-9876-hijk-543210987bca\",\n",
      "                \"Tweet_Text\": \"Salut à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-04-30 22:15:40\",\n",
      "                \"Likes_Count\": 80,\n",
      "                \"Retweets_Count\": 60,\n",
      "                \"Replies_Count\": 35\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234uv56-7890-wxyz-abcd-123456789uvw\",\n",
      "                \"User_ID\": \"8901rs23-tu45-vwxy-6789-012345678rst\",\n",
      "                \"Engaged_User_ID\": \"7654fghe-4321-9876-hijk-543210987bca\",\n",
      "                \"Engaged_At\": \"2021-09-20 08:40:10\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.19619771250032148.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"2345jk67-8901-lmno-3456-789012345def\",\n",
      "                \"Username\": \"fan789\",\n",
      "                \"Followers_Count\": 490,\n",
      "                \"Following_Count\": 320,\n",
      "                \"Tweet_Count\": 110,\n",
      "                \"Created_At\": \"2021-07-25 11:55:15\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"6789op01-2345-wxyz-bcde-678901234stu\",\n",
      "                \"User_ID\": \"2345jk67-8901-lmno-3456-789012345def\",\n",
      "                \"Tweet_Text\": \"Bonjour à tous!\",\n",
      "                \"Tweet_Created_At\": \"2021-10-15 18:25:50\",\n",
      "                \"Likes_Count\": 90,\n",
      "                \"Retweets_Count\": 50,\n",
      "                \"Replies_Count\": 30\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234rs56-7890-tuvw-abcd-123456789pqr\",\n",
      "                \"User_ID\": \"4567tu89-vw01-xyza-5678-901234567hij\",\n",
      "                \"Engaged_User_ID\": \"2345jk67-8901-lmno-3456-789012345def\",\n",
      "                \"Engaged_At\": \"2022-02-05 09:30:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.8261329822383832.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"7654dc32-1098-fghj-5432-987654321dcba\",\n",
      "                \"Username\": \"amoureuxTS\",\n",
      "                \"Followers_Count\": 600,\n",
      "                \"Following_Count\": 350,\n",
      "                \"Tweet_Count\": 130,\n",
      "                \"Created_At\": \"2020-12-02 09:45:30\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"9876ux54-3210-nmop-qwer-543216789vbnm\",\n",
      "                \"User_ID\": \"7654dc32-1098-fghj-5432-987654321dcba\",\n",
      "                \"Tweet_Text\": \"Vive Taylor Swift!\",\n",
      "                \"Tweet_Created_At\": \"2022-03-18 14:20:35\",\n",
      "                \"Likes_Count\": 80,\n",
      "                \"Retweets_Count\": 45,\n",
      "                \"Replies_Count\": 29\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"2345mn67-8901-kjhg-bvcd-876543210qwer\",\n",
      "                \"User_ID\": \"8901vb23-bnmk-hgfd-6789-432109876ytre\",\n",
      "                \"Engaged_User_ID\": \"7654dc32-1098-fghj-5432-987654321dcba\",\n",
      "                \"Engaged_At\": \"2021-11-30 08:10:25\",\n",
      "                \"Engagement_Type\": \"Retweet\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.48463978506266203.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"6543fe21-0987-bcde-7654-321098765abcd\",\n",
      "                \"Username\": \"Fan_de_Taylor\",\n",
      "                \"Followers_Count\": 470,\n",
      "                \"Following_Count\": 320,\n",
      "                \"Tweet_Count\": 110,\n",
      "                \"Created_At\": \"2021-08-25 12:15:20\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"4567ty89-0123-jklm-5678-901234567fghi\",\n",
      "                \"User_ID\": \"6543fe21-0987-bcde-7654-321098765abcd\",\n",
      "                \"Tweet_Text\": \"J'adore Taylor Swift!\",\n",
      "                \"Tweet_Created_At\": \"2022-04-10 17:30:40\",\n",
      "                \"Likes_Count\": 60,\n",
      "                \"Retweets_Count\": 35,\n",
      "                \"Replies_Count\": 22\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"7890ui12-3456-vbnm-qwerty-098765432jklm\",\n",
      "                \"User_ID\": \"2109zx87-6543-asdf-4321-876543210qwer\",\n",
      "                \"Engaged_User_ID\": \"6543fe21-0987-bcde-7654-321098765abcd\",\n",
      "                \"Engaged_At\": \"2021-12-20 10:25:30\",\n",
      "                \"Engagement_Type\": \"Réponse\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.8490363484137496.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: Taylor Swift fans ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"76543210-1234-abcd-5678-901234567890\",\n",
      "                \"Username\": \"Fan_de_Taylor_123\",\n",
      "                \"Followers_Count\": 520,\n",
      "                \"Following_Count\": 280,\n",
      "                \"Tweet_Count\": 80,\n",
      "                \"Created_At\": \"2020-10-12 09:45:30\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Profil utilisateur créé avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"23456789-8901-cdef-1234-567890123456\",\n",
      "                \"User_ID\": \"76543210-1234-abcd-5678-901234567890\",\n",
      "                \"Tweet_Text\": \"Vive Taylor Swift!\",\n",
      "                \"Tweet_Created_At\": \"2022-03-15 14:20:35\",\n",
      "                \"Likes_Count\": 80,\n",
      "                \"Retweets_Count\": 45,\n",
      "                \"Replies_Count\": 27\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet publié avec succès\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"89012345-2345-efgh-5678-912345678901\",\n",
      "                \"User_ID\": \"32109876-5432-cdef-8765-432109876543\",\n",
      "                \"Engaged_User_ID\": \"76543210-1234-abcd-5678-901234567890\",\n",
      "                \"Engaged_At\": \"2021-11-25 08:40:55\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement enregistré avec succès\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.Add Randomness: 0.7409366202374116.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Full Output in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more efficient data generation, especially when dealing with large datasets or multiple requests, our package supports parallel processing. This section covers how to utilize the consumeDataInParallel method of the DataConsumer class to generate your dataset asynchronously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Parallel Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure smooth parallel execution, especially within environments that don't natively support asynchronous operations (like Jupyter notebooks), we use nest_asyncio. This module allows asyncio to run inside environments with their own event loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:50.910810Z",
     "start_time": "2024-05-19T12:05:50.907400Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Full Output in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate data in parallel, use the generate_data_in_parallel coroutine. This method allows you to specify the query (if any), the number of records, region, and language, similarly to consumeData, but executes multiple data generation tasks concurrently.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:57.975730Z",
     "start_time": "2024-05-19T12:05:50.910810Z"
    }
   },
   "source": [
    "import asyncio\n",
    "generated_data = asyncio.run(DataAugmentorObj.generate_data_in_parallel(query = \"\", records=20, task_specifications=updated_task_specifications, region=region, language=language))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description:  ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): unknown.Add Randomness: 0.6109502744249932.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description:  ; The required region: France ; All texts should be translated to French language. ; The guidance given by an expert: 1. Données du profil utilisateur:\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Nom_utilisateur: texte libre\n",
      "   - Nombre_abonnés: numérique\n",
      "   - Nombre_abonnements: numérique\n",
      "   - Nombre_tweets: numérique\n",
      "   - Date_creation: datetime\n",
      "\n",
      "2. Données des tweets:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Texte_tweet: texte libre\n",
      "   - Date_creation_tweet: datetime\n",
      "   - Nombre_likes: numérique\n",
      "   - Nombre_retweets: numérique\n",
      "   - Nombre_réponses: numérique\n",
      "\n",
      "3. Données d'engagement:\n",
      "   - Identifiant_tweet: identifiant unique\n",
      "   - Identifiant_utilisateur: identifiant unique\n",
      "   - Identifiant_utilisateur_engagé: identifiant unique\n",
      "   - Date_engagement: datetime\n",
      "   - Type_engagement: catégorique (Like, Retweet, Réponse)\n",
      "\n",
      "4. Colonnes numériques:\n",
      "   - Nombre_abonnés: moyenne=500, écart-type=200, min=100, max=1000\n",
      "   - Nombre_abonnements: moyenne=300, écart-type=150, min=50, max=700\n",
      "   - Nombre_tweets: moyenne=100, écart-type=50, min=20, max=200\n",
      "   - Nombre_likes: moyenne=50, écart-type=20, min=10, max=100\n",
      "   - Nombre_retweets: moyenne=30, écart-type=10, min=5, max=60\n",
      "   - Nombre_réponses: moyenne=20, écart-type=8, min=5, max=40\n",
      "\n",
      "5. Colonnes catégoriques:\n",
      "   - Type_engagement: {Like: 0.5, Retweet: 0.3, Réponse: 0.2}\n",
      "\n",
      "6. Colonnes de texte libre:\n",
      "   - Nom_utilisateur: longueur moyenne=8, écart-type de la longueur=2\n",
      "   - Texte_tweet: longueur moyenne=50, écart-type de la longueur=10\n",
      "\n",
      "7. Colonnes d'identifiants uniques:\n",
      "   - Identifiant_utilisateur: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "   - Identifiant_tweet: format=UUID, regEX=[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\n",
      "\n",
      "8. Colonnes de date et heure:\n",
      "   - Date_creation: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_creation_tweet: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "   - Date_engagement: format=AAAA-MM-JJ HH:MM:SS, valeur min=2019-01-01 00:00:00, valeur max=2022-01-01 00:00:00\n",
      "\n",
      "9. Cette table a une nature transactionnelle car elle suit les interactions entre les utilisateurs et les tweets, telles que les likes, les retweets et les réponses...Required Structure: {\n",
      "    \"twitter_api\": [\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Username\": \"user123\",\n",
      "                \"Followers_Count\": 450,\n",
      "                \"Following_Count\": 250,\n",
      "                \"Tweet_Count\": 90,\n",
      "                \"Created_At\": \"2020-05-15 08:30:45\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"User profile created successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"1234cd56-7890-ab12-cdef-34567890abcd\",\n",
      "                \"User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Tweet_Text\": \"Hello world!\",\n",
      "                \"Tweet_Created_At\": \"2021-02-20 15:10:30\",\n",
      "                \"Likes_Count\": 70,\n",
      "                \"Retweets_Count\": 40,\n",
      "                \"Replies_Count\": 25\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Tweet posted successfully\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"input\": {\n",
      "                \"Tweet_ID\": \"5678ef90-1234-ab56-cdef-789012345678\",\n",
      "                \"User_ID\": \"2345bc67-8901-def2-3456-789012345abc\",\n",
      "                \"Engaged_User_ID\": \"0987ab12-3456-cdef-7890-123456789abc\",\n",
      "                \"Engaged_At\": \"2021-03-10 12:45:20\",\n",
      "                \"Engagement_Type\": \"Like\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"status\": \"Engagement recorded successfully\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}.The previous generated batch (maintain sequential patterns if needed): unknown.Add Randomness: 0.0618838521503442.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:57.987782Z",
     "start_time": "2024-05-19T12:05:57.975730Z"
    }
   },
   "source": [
    "generated_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twitter_api':                           input.User_ID  input.Username  \\\n",
       " 0  9876dcba-5432-fedc-7890-214365879bac  utilisateur456   \n",
       " 1  9876dcba-5432-fedc-7890-214365879bac             NaN   \n",
       " 2  1234ab56-7890-cd12-ef34-567890123def             NaN   \n",
       " 3  8a5f97b1-6fa3-4a17-aa3c-5dbb9bcdb914  utilisateur456   \n",
       " 4  8a5f97b1-6fa3-4a17-aa3c-5dbb9bcdb914             NaN   \n",
       " 5  a9ae06d9-7bdf-4cd7-bf12-07c4e36f84c9             NaN   \n",
       " \n",
       "    input.Followers_Count  input.Following_Count  input.Tweet_Count  \\\n",
       " 0                  420.0                  230.0               85.0   \n",
       " 1                    NaN                    NaN                NaN   \n",
       " 2                    NaN                    NaN                NaN   \n",
       " 3                  520.0                  320.0              110.0   \n",
       " 4                    NaN                    NaN                NaN   \n",
       " 5                    NaN                    NaN                NaN   \n",
       " \n",
       "       input.Created_At                        output.status  \\\n",
       " 0  2020-04-20 08:15:30  Profil utilisateur créé avec succès   \n",
       " 1                  NaN              Tweet posté avec succès   \n",
       " 2                  NaN    Engagement enregistré avec succès   \n",
       " 3  2019-07-14 09:22:58  Profil utilisateur créé avec succès   \n",
       " 4                  NaN             Tweet publié avec succès   \n",
       " 5                  NaN    Engagement enregistré avec succès   \n",
       " \n",
       "                          input.Tweet_ID        input.Tweet_Text  \\\n",
       " 0                                   NaN                     NaN   \n",
       " 1  3412dc56-7890-ba98-fedc-674589032abc         Bonjour à tous!   \n",
       " 2  8901fe67-2345-ba78-dcfe-901234567abc                     NaN   \n",
       " 3                                   NaN                     NaN   \n",
       " 4  3b27e77f-e7e3-4a6c-8d9e-148baeab44ae  Bonjour tout le monde!   \n",
       " 5  c0ef66e7-d515-4f49-ba67-8b0bbd35b5a6                     NaN   \n",
       " \n",
       "   input.Tweet_Created_At  input.Likes_Count  input.Retweets_Count  \\\n",
       " 0                    NaN                NaN                   NaN   \n",
       " 1    2021-01-15 10:45:20               65.0                  35.0   \n",
       " 2                    NaN                NaN                   NaN   \n",
       " 3                    NaN                NaN                   NaN   \n",
       " 4    2020-08-27 18:45:32               85.0                  35.0   \n",
       " 5                    NaN                NaN                   NaN   \n",
       " \n",
       "    input.Replies_Count                 input.Engaged_User_ID  \\\n",
       " 0                  NaN                                   NaN   \n",
       " 1                 20.0                                   NaN   \n",
       " 2                  NaN  9876dcba-5432-fedc-7890-214365879bac   \n",
       " 3                  NaN                                   NaN   \n",
       " 4                 22.0                                   NaN   \n",
       " 5                  NaN  8a5f97b1-6fa3-4a17-aa3c-5dbb9bcdb914   \n",
       " \n",
       "       input.Engaged_At input.Engagement_Type  \n",
       " 0                  NaN                   NaN  \n",
       " 1                  NaN                   NaN  \n",
       " 2  2021-02-25 14:30:15               Retweet  \n",
       " 3                  NaN                   NaN  \n",
       " 4                  NaN                   NaN  \n",
       " 5  2021-11-05 10:30:15               Réponse  }"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Example Data to Data Structure and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide outlines the process of extracting a data structure from a given CSV file and using that structure to generate new data. This is particularly useful when you have sample data and want to replicate its structure with new, synthesized content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data Structure from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, you'll need to specify the path to your CSV file and the file name. Then, use the create_json_sample_from_csv function to extract the data structure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:58.000228Z",
     "start_time": "2024-05-19T12:05:57.987782Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Specify the path and file name\n",
    "path = r'C:\\Users\\Sigal\\data\\\\'\n",
    "file_name = r\"titanic.csv\"\n",
    "\n",
    "# Extract data structure from the CSV file\n",
    "dataStructureSample = create_json_sample_from_csv(path, file_name)\n",
    "print(dataStructureSample)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"titanic.csv\": [{\"PassengerId\":531,\"Survived\":1,\"Pclass\":2,\"Name\":\"Quick, Miss. Phyllis May\",\"Sex\":\"female\",\"Age\":2.0,\"SibSp\":1,\"Parch\":1,\"Ticket\":\"26360\",\"Fare\":26.0,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":567,\"Survived\":0,\"Pclass\":3,\"Name\":\"Stoytcheff, Mr. Ilia\",\"Sex\":\"male\",\"Age\":19.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"349205\",\"Fare\":7.8958,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":746,\"Survived\":0,\"Pclass\":1,\"Name\":\"Crosby, Capt. Edward Gifford\",\"Sex\":\"male\",\"Age\":70.0,\"SibSp\":1,\"Parch\":1,\"Ticket\":\"WE\\/P 5735\",\"Fare\":71.0,\"Cabin\":\"B22\",\"Embarked\":\"S\"},{\"PassengerId\":371,\"Survived\":1,\"Pclass\":1,\"Name\":\"Harder, Mr. George Achilles\",\"Sex\":\"male\",\"Age\":25.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"11765\",\"Fare\":55.4417,\"Cabin\":\"E50\",\"Embarked\":\"C\"},{\"PassengerId\":572,\"Survived\":1,\"Pclass\":1,\"Name\":\"Appleton, Mrs. Edward Dale (Charlotte Lamson)\",\"Sex\":\"female\",\"Age\":53.0,\"SibSp\":2,\"Parch\":0,\"Ticket\":\"11769\",\"Fare\":51.4792,\"Cabin\":\"C101\",\"Embarked\":\"S\"}]}\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Data Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data structure extracted, you're ready to initialize the DataConsumer object that will be used for generating data.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:58.010115Z",
     "start_time": "2024-05-19T12:05:58.000228Z"
    }
   },
   "source": [
    "# Construct the full file path\n",
    "full_file_path = os.path.join(path, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(full_file_path)\n",
    "\n",
    "# Initialize the DataConsumer with the extracted data structure\n",
    "DataAugmentorObj = DataAugmentor(llm=llm, structure=dataStructureSample)"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Example Dataframe (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want the generated data to be influenced by examples from your original dataset, you can set an examples DataFrame within your DataConsumer object.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:05:58.015151Z",
     "start_time": "2024-05-19T12:05:58.011628Z"
    }
   },
   "source": [
    "DataAugmentorObj.set_examples_dataframe(df, file_name)"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and Preview Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can generate and preview the synthesized data based on the extracted structure and any example data provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:06:08.985942Z",
     "start_time": "2024-05-19T12:05:58.015151Z"
    }
   },
   "source": [
    "generated_data = DataAugmentorObj.preview_output_sample()\n",
    "print(generated_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in generating synthetic data according to user requests.Generate 10 Sample synthetic items(records in a table or the equivalent elements in unstructured text) for the data described below. In the following structure, but with different values.For the following task: Data description: None.Required Structure: {\"titanic.csv\": [{\"PassengerId\":557,\"Survived\":1,\"Pclass\":1,\"Name\":\"Duff Gordon, Lady. (Lucille Christiana Sutherland) (\\\\Mrs Morgan\\\\\\\")\\\"\",\"Sex\":\"female\",\"Age\":48.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"11755\",\"Fare\":39.6,\"Cabin\":\"A16\",\"Embarked\":\"C\"},{\"PassengerId\":342,\"Survived\":1,\"Pclass\":1,\"Name\":\"Fortune, Miss. Alice Elizabeth\",\"Sex\":\"female\",\"Age\":24.0,\"SibSp\":3,\"Parch\":2,\"Ticket\":\"19950\",\"Fare\":263.0,\"Cabin\":\"C23 C25 C27\",\"Embarked\":\"S\"},{\"PassengerId\":317,\"Survived\":1,\"Pclass\":2,\"Name\":\"Kantor, Mrs. Sinai (Miriam Sternin)\",\"Sex\":\"female\",\"Age\":24.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"244367\",\"Fare\":26.0,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":838,\"Survived\":0,\"Pclass\":3,\"Name\":\"Sirota, Mr. Maurice\",\"Sex\":\"male\",\"Age\":null,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"392092\",\"Fare\":8.05,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":142,\"Survived\":1,\"Pclass\":3,\"Name\":\"Nysten, Miss. Anna Sofia\",\"Sex\":\"female\",\"Age\":22.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"347081\",\"Fare\":7.75,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":687,\"Survived\":0,\"Pclass\":3,\"Name\":\"Panula, Mr. Jaako Arnold\",\"Sex\":\"male\",\"Age\":14.0,\"SibSp\":4,\"Parch\":1,\"Ticket\":\"3101295\",\"Fare\":39.6875,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":254,\"Survived\":0,\"Pclass\":3,\"Name\":\"Lobb, Mr. William Arthur\",\"Sex\":\"male\",\"Age\":30.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"A\\/5. 3336\",\"Fare\":16.1,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":556,\"Survived\":0,\"Pclass\":1,\"Name\":\"Wright, Mr. George\",\"Sex\":\"male\",\"Age\":62.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"113807\",\"Fare\":26.55,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":409,\"Survived\":0,\"Pclass\":3,\"Name\":\"Birkeland, Mr. Hans Martin Monsen\",\"Sex\":\"male\",\"Age\":21.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"312992\",\"Fare\":7.775,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":551,\"Survived\":1,\"Pclass\":1,\"Name\":\"Thayer, Mr. John Borland Jr\",\"Sex\":\"male\",\"Age\":17.0,\"SibSp\":0,\"Parch\":2,\"Ticket\":\"17421\",\"Fare\":110.8833,\"Cabin\":\"C70\",\"Embarked\":\"C\"}]}.The previous generated batch (maintain sequential patterns if needed): unknown.Add Randomness: 0.10380643184596994.It is critical that you don't repeat the same values every time you get this prompt.\n",
      "Generated Output:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'titanic.csv':    PassengerId  Survived  Pclass  \\\n",
      "0          732         1       2   \n",
      "1          469         0       3   \n",
      "2          193         1       3   \n",
      "3          442         0       3   \n",
      "4          613         0       3   \n",
      "5          153         0       3   \n",
      "6          661         1       1   \n",
      "7          808         0       3   \n",
      "8           41         0       3   \n",
      "9          731         1       1   \n",
      "\n",
      "                                              Name     Sex   Age  SibSp  \\\n",
      "0                             Knight, Mr. Robert J    male  36.0      0   \n",
      "1                               Scanlan, Mr. James    male   NaN      0   \n",
      "2  Andersen-Jensen, Miss. Carla Christine Nielsine  female  19.0      1   \n",
      "3                                  Hampe, Mr. Leon    male  20.0      0   \n",
      "4                      Murphy, Miss. Margaret Jane  female   NaN      1   \n",
      "5                                 Meo, Mr. Alfonzo    male  55.5      0   \n",
      "6                    Frauenthal, Dr. Henry William    male  50.0      2   \n",
      "7                  Pettersson, Miss. Ellen Natalia  female  18.0      0   \n",
      "8                              Ahlin, Mrs. Johanne  female  40.0      1   \n",
      "9                    Allen, Miss. Elisabeth Walton  female  29.0      0   \n",
      "\n",
      "   Parch      Ticket      Fare Cabin Embarked  \n",
      "0      0      239855    0.0000  None        S  \n",
      "1      0       36209    7.7250  None        Q  \n",
      "2      0      350046    7.8542  None        S  \n",
      "3      0      345769    9.5000  None        S  \n",
      "4      0      367230   15.5000  None        Q  \n",
      "5      0  A.5. 11206    8.0500  None        S  \n",
      "6      0    PC 17611  133.6500  None        S  \n",
      "7      0      347087    7.7750  None        S  \n",
      "8      0        7546    9.4750  None        S  \n",
      "9      0       24160  211.3375    B5        S  }\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Source Data with a textual description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the DataTransformer to apply transformations to the source data based on a given description. This could be used for data enrichment, data preparation and data explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to add a field indicating the main explanation for each passenger's survival in the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:06:08.989802Z",
     "start_time": "2024-05-19T12:06:08.986952Z"
    }
   },
   "source": [
    "from src.DataTransformer import DataTransformer  # Assuming the necessary import"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:06:08.994318Z",
     "start_time": "2024-05-19T12:06:08.990813Z"
    }
   },
   "source": [
    "# Instantiate the DataTransformer with the language model\n",
    "DataTransformerObj = DataTransformer(llm=llm)"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:06:21.937087Z",
     "start_time": "2024-05-19T12:06:08.995323Z"
    }
   },
   "source": [
    "# Define the transformation based on a user's description and apply it to the data.\n",
    "query = \"Could you add a field indicating the main explanation for the survival of each passenger?\"\n",
    "results = DataTransformerObj.define_transformation(source_data={\"titanic\": df}, description=query)\n",
    "print(\"Transformed Sample Data:\")\n",
    "print(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\":865,\"Survived\":0,\"Pclass\":2,\"Name\":\"Gill, Mr. John William\",\"Sex\":\"male\",\"Age\":24.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"233866\",\"Fare\":13.0,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":46,\"Survived\":0,\"Pclass\":3,\"Name\":\"Rogers, Mr. William John\",\"Sex\":\"male\",\"Age\":null,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"S.C.\\/A.4. 23567\",\"Fare\":8.05,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":73,\"Survived\":0,\"Pclass\":2,\"Name\":\"Hood, Mr. Ambrose Jr\",\"Sex\":\"male\",\"Age\":21.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"S.O.C. 14879\",\"Fare\":73.5,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":725,\"Survived\":1,\"Pclass\":1,\"Name\":\"Chambers, Mr. Norman Campbell\",\"Sex\":\"male\",\"Age\":27.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"113806\",\"Fare\":53.1,\"Cabin\":\"E8\",\"Embarked\":\"S\"},{\"PassengerId\":484,\"Survived\":1,\"Pclass\":3,\"Name\":\"Turkula, Mrs. (Hedwig)\",\"Sex\":\"female\",\"Age\":63.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"4134\",\"Fare\":9.5875,\"Cabin\":null,\"Embarked\":\"S\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Transformed Sample Data:\n",
      "{\n",
      "  \"titanic\": [\n",
      "    {\n",
      "      \"PassengerId\": 865,\n",
      "      \"Survived\": 0,\n",
      "      \"Pclass\": 2,\n",
      "      \"Name\": \"Gill, Mr. John William\",\n",
      "      \"Sex\": \"male\",\n",
      "      \"Age\": 24.0,\n",
      "      \"SibSp\": 0,\n",
      "      \"Parch\": 0,\n",
      "      \"Ticket\": \"233866\",\n",
      "      \"Fare\": 13.0,\n",
      "      \"Cabin\": null,\n",
      "      \"Embarked\": \"S\",\n",
      "      \"Survival_Reason\": \"Not meeting common factors for survival\"\n",
      "    },\n",
      "    {\n",
      "      \"PassengerId\": 46,\n",
      "      \"Survived\": 0,\n",
      "      \"Pclass\": 3,\n",
      "      \"Name\": \"Rogers, Mr. William John\",\n",
      "      \"Sex\": \"male\",\n",
      "      \"Age\": null,\n",
      "      \"SibSp\": 0,\n",
      "      \"Parch\": 0,\n",
      "      \"Ticket\": \"S.C./A.4. 23567\",\n",
      "      \"Fare\": 8.05,\n",
      "      \"Cabin\": null,\n",
      "      \"Embarked\": \"S\",\n",
      "      \"Survival_Reason\": \"Not meeting common factors for survival\"\n",
      "    },\n",
      "    {\n",
      "      \"PassengerId\": 72,\n",
      "      \"Survived\": 0,\n",
      "      \"Pclass\": 2,\n",
      "      \"Name\": \"Hood, Mr. Ambrose Jr\",\n",
      "      \"Sex\": \"male\",\n",
      "      \"Age\": 21.0,\n",
      "      \"SibSp\": 0,\n",
      "      \"Parch\": 0,\n",
      "      \"Ticket\": \"S.O.C. 14879\",\n",
      "      \"Fare\": 73.5,\n",
      "      \"Cabin\": null,\n",
      "      \"Embarked\": \"S\",\n",
      "      \"Survival_Reason\": \"Not meeting common factors for survival\"\n",
      "    },\n",
      "    {\n",
      "      \"PassengerId\": 725,\n",
      "      \"Survived\": 1,\n",
      "      \"Pclass\": 1,\n",
      "      \"Name\": \"Chambers, Mr. Norman Campbell\",\n",
      "      \"Sex\": \"male\",\n",
      "      \"Age\": 27.0,\n",
      "      \"SibSp\": 1,\n",
      "      \"Parch\": 0,\n",
      "      \"Ticket\": \"113806\",\n",
      "      \"Fare\": 53.1,\n",
      "      \"Cabin\": \"E8\",\n",
      "      \"Embarked\": \"S\",\n",
      "      \"Survival_Reason\": \"Meeting common factors for survival\"\n",
      "    },\n",
      "    {\n",
      "      \"PassengerId\": 483,\n",
      "      \"Survived\": 1,\n",
      "      \"Pclass\": 3,\n",
      "      \"Name\": \"Turkula, Mrs. (Hedwig)\",\n",
      "      \"Sex\": \"female\",\n",
      "      \"Age\": 63.0,\n",
      "      \"SibSp\": 0,\n",
      "      \"Parch\": 0,\n",
      "      \"Ticket\": \"4134\",\n",
      "      \"Fare\": 9.5875,\n",
      "      \"Cabin\": null,\n",
      "      \"Embarked\": \"S\",\n",
      "      \"Survival_Reason\": \"Meeting common factors for survival\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Full Output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:06.452096Z",
     "start_time": "2024-05-19T12:06:21.938092Z"
    }
   },
   "source": [
    "# Apply the transformation to the source data and print the results.\n",
    "results = DataTransformerObj.transform(source_data={\"titanic\": df[:50]})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 1, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Braund, Mr. Owen Harris\", \"Sex\": \"male\", \"Age\": 22.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"A/5 21171\", \"Fare\": 7.25, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 2, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Sex\": \"female\", \"Age\": 38.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17599\", \"Fare\": 71.2833, \"Cabin\": \"C85\", \"Embarked\": \"C\"}, {\"PassengerId\": 3, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Heikkinen, Miss. Laina\", \"Sex\": \"female\", \"Age\": 26.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"STON/O2. 3101282\", \"Fare\": 7.925, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 4, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Sex\": \"female\", \"Age\": 35.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"113803\", \"Fare\": 53.1, \"Cabin\": \"C123\", \"Embarked\": \"S\"}, {\"PassengerId\": 5, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Allen, Mr. William Henry\", \"Sex\": \"male\", \"Age\": 35.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"373450\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 6, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Moran, Mr. James\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330877\", \"Fare\": 8.4583, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 7, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"McCarthy, Mr. Timothy J\", \"Sex\": \"male\", \"Age\": 54.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"17463\", \"Fare\": 51.8625, \"Cabin\": \"E46\", \"Embarked\": \"S\"}, {\"PassengerId\": 8, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Palsson, Master. Gosta Leonard\", \"Sex\": \"male\", \"Age\": 2.0, \"SibSp\": 3, \"Parch\": 1, \"Ticket\": \"349909\", \"Fare\": 21.075, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 9, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\", \"Sex\": \"female\", \"Age\": 27.0, \"SibSp\": 0, \"Parch\": 2, \"Ticket\": \"347742\", \"Fare\": 11.1333, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 10, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"237736\", \"Fare\": 30.0708, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 11, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Sandstrom, Miss. Marguerite Rut\", \"Sex\": \"female\", \"Age\": 4.0, \"SibSp\": 1, \"Parch\": 1, \"Ticket\": \"PP 9549\", \"Fare\": 16.7, \"Cabin\": \"G6\", \"Embarked\": \"S\"}, {\"PassengerId\": 12, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Bonnell, Miss. Elizabeth\", \"Sex\": \"female\", \"Age\": 58.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"113783\", \"Fare\": 26.55, \"Cabin\": \"C103\", \"Embarked\": \"S\"}, {\"PassengerId\": 13, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Saundercock, Mr. William Henry\", \"Sex\": \"male\", \"Age\": 20.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"A/5. 2151\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 14, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Andersson, Mr. Anders Johan\", \"Sex\": \"male\", \"Age\": 39.0, \"SibSp\": 1, \"Parch\": 5, \"Ticket\": \"347082\", \"Fare\": 31.275, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 15, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vestrom, Miss. Hulda Amanda Adolfina\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"350406\", \"Fare\": 7.8542, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 16, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Hewlett, Mrs. (Mary D Kingcome) \", \"Sex\": \"female\", \"Age\": 55.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"248706\", \"Fare\": 16.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 17, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Rice, Master. Eugene\", \"Sex\": \"male\", \"Age\": 2.0, \"SibSp\": 4, \"Parch\": 1, \"Ticket\": \"382652\", \"Fare\": 29.125, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 18, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Williams, Mr. Charles Eugene\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"244373\", \"Fare\": 13.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 19, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)\", \"Sex\": \"female\", \"Age\": 31.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"345763\", \"Fare\": 18.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 20, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Masselmani, Mrs. Fatima\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2649\", \"Fare\": 7.225, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 21, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Fynney, Mr. Joseph J\", \"Sex\": \"male\", \"Age\": 35.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"239865\", \"Fare\": 26.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 22, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Beesley, Mr. Lawrence\", \"Sex\": \"male\", \"Age\": 34.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"248698\", \"Fare\": 13.0, \"Cabin\": \"D56\", \"Embarked\": \"S\"}, {\"PassengerId\": 23, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"McGowan, Miss. Anna \\\\Annie\\\\\\\"\\\"\", \"Sex\": \"female\", \"Age\": 15.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330923\", \"Fare\": 8.0292, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 24, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Sloper, Mr. William Thompson\", \"Sex\": \"male\", \"Age\": 28.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"113788\", \"Fare\": 35.5, \"Cabin\": \"A6\", \"Embarked\": \"S\"}, {\"PassengerId\": 25, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Palsson, Miss. Torborg Danira\", \"Sex\": \"female\", \"Age\": 8.0, \"SibSp\": 3, \"Parch\": 1, \"Ticket\": \"349909\", \"Fare\": 21.075, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 26, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)\", \"Sex\": \"female\", \"Age\": 38.0, \"SibSp\": 1, \"Parch\": 5, \"Ticket\": \"347077\", \"Fare\": 31.3875, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 27, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Emir, Mr. Farred Chehab\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2631\", \"Fare\": 7.225, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 28, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Fortune, Mr. Charles Alexander\", \"Sex\": \"male\", \"Age\": 19.0, \"SibSp\": 3, \"Parch\": 2, \"Ticket\": \"19950\", \"Fare\": 263.0, \"Cabin\": \"C23 C25 C27\", \"Embarked\": \"S\"}, {\"PassengerId\": 29, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"O'Dwyer, Miss. Ellen \\\\Nellie\\\\\\\"\\\"\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330959\", \"Fare\": 7.8792, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 30, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Todoroff, Mr. Lalio\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"349216\", \"Fare\": 7.8958, \"Cabin\": NaN, \"Embarked\": \"S\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 31, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Uruchurtu, Don. Manuel E\", \"Sex\": \"male\", \"Age\": 40.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"PC 17601\", \"Fare\": 27.7208, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 32, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Spencer, Mrs. William Augustus (Marie Eugenie)\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17569\", \"Fare\": 146.5208, \"Cabin\": \"B78\", \"Embarked\": \"C\"}, {\"PassengerId\": 33, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Glynn, Miss. Mary Agatha\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"335677\", \"Fare\": 7.75, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 34, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Wheadon, Mr. Edward H\", \"Sex\": \"male\", \"Age\": 66.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"C.A. 24579\", \"Fare\": 10.5, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 35, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Meyer, Mr. Edgar Joseph\", \"Sex\": \"male\", \"Age\": 28.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17604\", \"Fare\": 82.1708, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 36, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Holverson, Mr. Alexander Oskar\", \"Sex\": \"male\", \"Age\": 42.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"113789\", \"Fare\": 52.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 37, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Mamee, Mr. Hanna\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2677\", \"Fare\": 7.2292, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 38, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Cann, Mr. Ernest Charles\", \"Sex\": \"male\", \"Age\": 21.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"A./5. 2152\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 39, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vander Planke, Miss. Augusta Maria\", \"Sex\": \"female\", \"Age\": 18.0, \"SibSp\": 2, \"Parch\": 0, \"Ticket\": \"345764\", \"Fare\": 18.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 40, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Nicola-Yarred, Miss. Jamila\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"2651\", \"Fare\": 11.2417, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 41, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Ahlin, Mrs. Johan (Johanna Persdotter Larsson)\", \"Sex\": \"female\", \"Age\": 40.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"7546\", \"Fare\": 9.475, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 42, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Turpin, Mrs. William John Robert (Dorothy Ann Wonnacott)\", \"Sex\": \"female\", \"Age\": 27.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"11668\", \"Fare\": 21.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 43, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Kraeff, Mr. Theodor\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"349253\", \"Fare\": 7.8958, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 44, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Laroche, Miss. Simonne Marie Anne Andree\", \"Sex\": \"female\", \"Age\": 3.0, \"SibSp\": 1, \"Parch\": 2, \"Ticket\": \"SC/Paris 2123\", \"Fare\": 41.5792, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 45, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Devaney, Miss. Margaret Delia\", \"Sex\": \"female\", \"Age\": 19.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330958\", \"Fare\": 7.8792, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 46, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Rogers, Mr. William John\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"S.C./A.4. 23567\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 47, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Lennon, Mr. Denis\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"370371\", \"Fare\": 15.5, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 48, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"O'Driscoll, Miss. Bridget\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"14311\", \"Fare\": 7.75, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 49, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Samaan, Mr. Youssef\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 2, \"Parch\": 0, \"Ticket\": \"2662\", \"Fare\": 21.6792, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 50, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Arnold-Franchi, Mrs. Josef (Josefine Franchi)\", \"Sex\": \"female\", \"Age\": 18.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"349237\", \"Fare\": 17.8, \"Cabin\": NaN, \"Embarked\": \"S\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:06.480421Z",
     "start_time": "2024-05-19T12:08:06.453101Z"
    }
   },
   "source": [
    "pd.DataFrame(results['titanic'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "15           16         1       2   \n",
       "16           17         0       3   \n",
       "17           18         1       2   \n",
       "18           19         0       3   \n",
       "19           20         1       3   \n",
       "20           21         0       2   \n",
       "21           22         1       2   \n",
       "22           23         1       3   \n",
       "23           24         1       1   \n",
       "24           25         0       3   \n",
       "25           26         1       3   \n",
       "26           27         0       3   \n",
       "27           28         0       1   \n",
       "28           29         1       3   \n",
       "29           30         0       3   \n",
       "30           31         0       1   \n",
       "31           32         1       1   \n",
       "32           33         1       3   \n",
       "33           34         0       2   \n",
       "34           35         0       1   \n",
       "35           36         0       1   \n",
       "36           37         1       3   \n",
       "37           38         0       3   \n",
       "38           39         0       3   \n",
       "39           40         1       3   \n",
       "40           41         0       3   \n",
       "41           42         0       2   \n",
       "42           43         0       3   \n",
       "43           44         1       2   \n",
       "44           45         1       3   \n",
       "45           46         0       3   \n",
       "46           47         0       3   \n",
       "47           48         1       3   \n",
       "48           49         0       3   \n",
       "49           50         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)  female  55.0      0   \n",
       "16                               Rice, Master. Eugene    male   2.0      4   \n",
       "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                               Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                        McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                      Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                            Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                     Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                      O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                Todoroff, Mr. Lalio    male   NaN      0   \n",
       "30                           Uruchurtu, Don. Manuel E    male  40.0      0   \n",
       "31     Spencer, Mrs. William Augustus (Marie Eugenie)  female   NaN      1   \n",
       "32                           Glynn, Miss. Mary Agatha  female   NaN      0   \n",
       "33                              Wheadon, Mr. Edward H    male  66.0      0   \n",
       "34                            Meyer, Mr. Edgar Joseph    male  28.0      1   \n",
       "35                     Holverson, Mr. Alexander Oskar    male  42.0      1   \n",
       "36                                   Mamee, Mr. Hanna    male   NaN      0   \n",
       "37                           Cann, Mr. Ernest Charles    male  21.0      0   \n",
       "38                 Vander Planke, Miss. Augusta Maria  female  18.0      2   \n",
       "39                        Nicola-Yarred, Miss. Jamila  female  14.0      1   \n",
       "40     Ahlin, Mrs. Johan (Johanna Persdotter Larsson)  female  40.0      1   \n",
       "41  Turpin, Mrs. William John Robert (Dorothy Ann ...  female  27.0      1   \n",
       "42                                Kraeff, Mr. Theodor    male   NaN      0   \n",
       "43           Laroche, Miss. Simonne Marie Anne Andree  female   3.0      1   \n",
       "44                      Devaney, Miss. Margaret Delia  female  19.0      0   \n",
       "45                           Rogers, Mr. William John    male   NaN      0   \n",
       "46                                  Lennon, Mr. Denis    male   NaN      1   \n",
       "47                          O'Driscoll, Miss. Bridget  female   NaN      0   \n",
       "48                                Samaan, Mr. Youssef    male   NaN      2   \n",
       "49      Arnold-Franchi, Mrs. Josef (Josefine Franchi)  female  18.0      1   \n",
       "\n",
       "    Parch            Ticket      Fare        Cabin Embarked  \\\n",
       "0       0         A/5 21171    7.2500          NaN        S   \n",
       "1       0          PC 17599   71.2833          C85        C   \n",
       "2       0  STON/O2. 3101282    7.9250          NaN        S   \n",
       "3       0            113803   53.1000         C123        S   \n",
       "4       0            373450    8.0500          NaN        S   \n",
       "5       0            330877    8.4583          NaN        Q   \n",
       "6       0             17463   51.8625          E46        S   \n",
       "7       1            349909   21.0750          NaN        S   \n",
       "8       2            347742   11.1333          NaN        S   \n",
       "9       0            237736   30.0708          NaN        C   \n",
       "10      1           PP 9549   16.7000           G6        S   \n",
       "11      0            113783   26.5500         C103        S   \n",
       "12      0         A/5. 2151    8.0500         None        S   \n",
       "13      5            347082   31.2750         None        S   \n",
       "14      0            350406    7.8542         None        S   \n",
       "15      0            248706   16.0000         None        S   \n",
       "16      1            382652   29.1250         None        Q   \n",
       "17      0            244373   13.0000         None        S   \n",
       "18      0            345763   18.0000         None        S   \n",
       "19      0              2649    7.2250         None        C   \n",
       "20      0            239865   26.0000         None        S   \n",
       "21      0            248698   13.0000          D56        S   \n",
       "22      0            330923    8.0292         None        Q   \n",
       "23      0            113788   35.5000           A6        S   \n",
       "24      1            349909   21.0750         None        S   \n",
       "25      5            347077   31.3875         None        S   \n",
       "26      0              2631    7.2250         None        C   \n",
       "27      2             19950  263.0000  C23 C25 C27        S   \n",
       "28      0            330959    7.8792         None        Q   \n",
       "29      0            349216    7.8958         None        S   \n",
       "30      0          PC 17601   27.7208          NaN        C   \n",
       "31      0          PC 17569  146.5208          B78        C   \n",
       "32      0            335677    7.7500          NaN        Q   \n",
       "33      0        C.A. 24579   10.5000          NaN        S   \n",
       "34      0          PC 17604   82.1708          NaN        C   \n",
       "35      0            113789   52.0000          NaN        S   \n",
       "36      0              2677    7.2292          NaN        C   \n",
       "37      0        A./5. 2152    8.0500          NaN        S   \n",
       "38      0            345764   18.0000          NaN        S   \n",
       "39      0              2651   11.2417          NaN        C   \n",
       "40      0              7546    9.4750          NaN        S   \n",
       "41      0             11668   21.0000          NaN        S   \n",
       "42      0            349253    7.8958          NaN        C   \n",
       "43      2     SC/Paris 2123   41.5792          NaN        C   \n",
       "44      0            330958    7.8792          NaN        Q   \n",
       "45      0   S.C./A.4. 23567    8.0500          NaN        S   \n",
       "46      0            370371   15.5000          NaN        Q   \n",
       "47      0             14311    7.7500          NaN        Q   \n",
       "48      0              2662   21.6792          NaN        C   \n",
       "49      0            349237   17.8000          NaN        S   \n",
       "\n",
       "                                      Survival_Reason  \n",
       "0                              Low chance of survival  \n",
       "1                             High chance of survival  \n",
       "2                             High chance of survival  \n",
       "3                             High chance of survival  \n",
       "4                              Low chance of survival  \n",
       "5                                             Unknown  \n",
       "6                              Low chance of survival  \n",
       "7                              Low chance of survival  \n",
       "8                             High chance of survival  \n",
       "9                             High chance of survival  \n",
       "10                                       Being female  \n",
       "11                                       Being female  \n",
       "12                                      Other factors  \n",
       "13                                      Other factors  \n",
       "14                                       Being female  \n",
       "15                                       Being female  \n",
       "16                                      Other factors  \n",
       "17                                      Other factors  \n",
       "18                                       Being female  \n",
       "19                                       Being female  \n",
       "20  Low chance of survival based on being male and...  \n",
       "21  Higher chance of survival based on being male ...  \n",
       "22  Higher chance of survival based on being femal...  \n",
       "23  Higher chance of survival based on being male ...  \n",
       "24  Low chance of survival based on being female, ...  \n",
       "25  Higher chance of survival based on being femal...  \n",
       "26  Low chance of survival based on being male and...  \n",
       "27  Low chance of survival based on being male, ha...  \n",
       "28  Higher chance of survival based on being femal...  \n",
       "29  Low chance of survival based on being male and...  \n",
       "30                             Low chance of survival  \n",
       "31                            High chance of survival  \n",
       "32                            High chance of survival  \n",
       "33                             Low chance of survival  \n",
       "34                             Low chance of survival  \n",
       "35                             Low chance of survival  \n",
       "36                            High chance of survival  \n",
       "37                             Low chance of survival  \n",
       "38                            High chance of survival  \n",
       "39                            High chance of survival  \n",
       "40                                             Female  \n",
       "41                                             Female  \n",
       "42                                               None  \n",
       "43                         Female, Young, With Family  \n",
       "44                                      Female, Young  \n",
       "45                                               None  \n",
       "46                                               None  \n",
       "47                                             Female  \n",
       "48                                               None  \n",
       "49                                      Female, Young  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survival_Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Other factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Other factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Other factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Other factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>Being female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>Higher chance of survival based on being male ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Higher chance of survival based on being femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>Higher chance of survival based on being male ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being female, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Higher chance of survival based on being femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>Low chance of survival based on being male and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Higher chance of survival based on being femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Uruchurtu, Don. Manuel E</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17601</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spencer, Mrs. William Augustus (Marie Eugenie)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B78</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wheadon, Mr. Edward H</td>\n",
       "      <td>male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 24579</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mr. Edgar Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Holverson, Mr. Alexander Oskar</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113789</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mamee, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cann, Mr. Ernest Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A./5. 2152</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Miss. Augusta Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>345764</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicola-Yarred, Miss. Jamila</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ahlin, Mrs. Johan (Johanna Persdotter Larsson)</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7546</td>\n",
       "      <td>9.4750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Turpin, Mrs. William John Robert (Dorothy Ann ...</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11668</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kraeff, Mr. Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349253</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Female, Young, With Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Devaney, Miss. Margaret Delia</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330958</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Female, Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rogers, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.C./A.4. 23567</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lennon, Mr. Denis</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>370371</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Driscoll, Miss. Bridget</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14311</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Samaan, Mr. Youssef</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2662</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Arnold-Franchi, Mrs. Josef (Josefine Franchi)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>349237</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Female, Young</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Full Output in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:06.484454Z",
     "start_time": "2024-05-19T12:08:06.481427Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Full Output in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the transformation on a subset of the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Heree, the first 45 records of the Titanic dataset are processed in parallel using the asynchronous method.# The output is then collected and converted into a pandas DataFrame for easy viewing and further analysi.\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:35.525106Z",
     "start_time": "2024-05-19T12:08:06.485460Z"
    }
   },
   "source": [
    "generated_data = asyncio.run(DataTransformerObj.transform_in_parallel(source_data={\"titanic\":df[:45]}))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 11, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Sandstrom, Miss. Marguerite Rut\", \"Sex\": \"female\", \"Age\": 4.0, \"SibSp\": 1, \"Parch\": 1, \"Ticket\": \"PP 9549\", \"Fare\": 16.7, \"Cabin\": \"G6\", \"Embarked\": \"S\"}, {\"PassengerId\": 12, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Bonnell, Miss. Elizabeth\", \"Sex\": \"female\", \"Age\": 58.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"113783\", \"Fare\": 26.55, \"Cabin\": \"C103\", \"Embarked\": \"S\"}, {\"PassengerId\": 13, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Saundercock, Mr. William Henry\", \"Sex\": \"male\", \"Age\": 20.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"A/5. 2151\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 14, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Andersson, Mr. Anders Johan\", \"Sex\": \"male\", \"Age\": 39.0, \"SibSp\": 1, \"Parch\": 5, \"Ticket\": \"347082\", \"Fare\": 31.275, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 15, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vestrom, Miss. Hulda Amanda Adolfina\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"350406\", \"Fare\": 7.8542, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 16, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Hewlett, Mrs. (Mary D Kingcome) \", \"Sex\": \"female\", \"Age\": 55.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"248706\", \"Fare\": 16.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 17, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Rice, Master. Eugene\", \"Sex\": \"male\", \"Age\": 2.0, \"SibSp\": 4, \"Parch\": 1, \"Ticket\": \"382652\", \"Fare\": 29.125, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 18, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Williams, Mr. Charles Eugene\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"244373\", \"Fare\": 13.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 19, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)\", \"Sex\": \"female\", \"Age\": 31.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"345763\", \"Fare\": 18.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 20, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Masselmani, Mrs. Fatima\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2649\", \"Fare\": 7.225, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 21, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Fynney, Mr. Joseph J\", \"Sex\": \"male\", \"Age\": 35.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"239865\", \"Fare\": 26.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 22, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Beesley, Mr. Lawrence\", \"Sex\": \"male\", \"Age\": 34.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"248698\", \"Fare\": 13.0, \"Cabin\": \"D56\", \"Embarked\": \"S\"}, {\"PassengerId\": 23, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"McGowan, Miss. Anna \\\\Annie\\\\\\\"\\\"\", \"Sex\": \"female\", \"Age\": 15.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330923\", \"Fare\": 8.0292, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 24, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Sloper, Mr. William Thompson\", \"Sex\": \"male\", \"Age\": 28.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"113788\", \"Fare\": 35.5, \"Cabin\": \"A6\", \"Embarked\": \"S\"}, {\"PassengerId\": 25, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Palsson, Miss. Torborg Danira\", \"Sex\": \"female\", \"Age\": 8.0, \"SibSp\": 3, \"Parch\": 1, \"Ticket\": \"349909\", \"Fare\": 21.075, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 26, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)\", \"Sex\": \"female\", \"Age\": 38.0, \"SibSp\": 1, \"Parch\": 5, \"Ticket\": \"347077\", \"Fare\": 31.3875, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 27, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Emir, Mr. Farred Chehab\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2631\", \"Fare\": 7.225, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 28, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Fortune, Mr. Charles Alexander\", \"Sex\": \"male\", \"Age\": 19.0, \"SibSp\": 3, \"Parch\": 2, \"Ticket\": \"19950\", \"Fare\": 263.0, \"Cabin\": \"C23 C25 C27\", \"Embarked\": \"S\"}, {\"PassengerId\": 29, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"O'Dwyer, Miss. Ellen \\\\Nellie\\\\\\\"\\\"\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330959\", \"Fare\": 7.8792, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 30, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Todoroff, Mr. Lalio\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"349216\", \"Fare\": 7.8958, \"Cabin\": NaN, \"Embarked\": \"S\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 1, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Braund, Mr. Owen Harris\", \"Sex\": \"male\", \"Age\": 22.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"A/5 21171\", \"Fare\": 7.25, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 2, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Sex\": \"female\", \"Age\": 38.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17599\", \"Fare\": 71.2833, \"Cabin\": \"C85\", \"Embarked\": \"C\"}, {\"PassengerId\": 3, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Heikkinen, Miss. Laina\", \"Sex\": \"female\", \"Age\": 26.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"STON/O2. 3101282\", \"Fare\": 7.925, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 4, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Sex\": \"female\", \"Age\": 35.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"113803\", \"Fare\": 53.1, \"Cabin\": \"C123\", \"Embarked\": \"S\"}, {\"PassengerId\": 5, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Allen, Mr. William Henry\", \"Sex\": \"male\", \"Age\": 35.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"373450\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 6, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Moran, Mr. James\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330877\", \"Fare\": 8.4583, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 7, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"McCarthy, Mr. Timothy J\", \"Sex\": \"male\", \"Age\": 54.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"17463\", \"Fare\": 51.8625, \"Cabin\": \"E46\", \"Embarked\": \"S\"}, {\"PassengerId\": 8, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Palsson, Master. Gosta Leonard\", \"Sex\": \"male\", \"Age\": 2.0, \"SibSp\": 3, \"Parch\": 1, \"Ticket\": \"349909\", \"Fare\": 21.075, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 9, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\", \"Sex\": \"female\", \"Age\": 27.0, \"SibSp\": 0, \"Parch\": 2, \"Ticket\": \"347742\", \"Fare\": 11.1333, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 10, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"237736\", \"Fare\": 30.0708, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 31, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Uruchurtu, Don. Manuel E\", \"Sex\": \"male\", \"Age\": 40.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"PC 17601\", \"Fare\": 27.7208, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 32, \"Survived\": 1, \"Pclass\": 1, \"Name\": \"Spencer, Mrs. William Augustus (Marie Eugenie)\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17569\", \"Fare\": 146.5208, \"Cabin\": \"B78\", \"Embarked\": \"C\"}, {\"PassengerId\": 33, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Glynn, Miss. Mary Agatha\", \"Sex\": \"female\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"335677\", \"Fare\": 7.75, \"Cabin\": NaN, \"Embarked\": \"Q\"}, {\"PassengerId\": 34, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Wheadon, Mr. Edward H\", \"Sex\": \"male\", \"Age\": 66.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"C.A. 24579\", \"Fare\": 10.5, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 35, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Meyer, Mr. Edgar Joseph\", \"Sex\": \"male\", \"Age\": 28.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"PC 17604\", \"Fare\": 82.1708, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 36, \"Survived\": 0, \"Pclass\": 1, \"Name\": \"Holverson, Mr. Alexander Oskar\", \"Sex\": \"male\", \"Age\": 42.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"113789\", \"Fare\": 52.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 37, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Mamee, Mr. Hanna\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"2677\", \"Fare\": 7.2292, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 38, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Cann, Mr. Ernest Charles\", \"Sex\": \"male\", \"Age\": 21.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"A./5. 2152\", \"Fare\": 8.05, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 39, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Vander Planke, Miss. Augusta Maria\", \"Sex\": \"female\", \"Age\": 18.0, \"SibSp\": 2, \"Parch\": 0, \"Ticket\": \"345764\", \"Fare\": 18.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 40, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Nicola-Yarred, Miss. Jamila\", \"Sex\": \"female\", \"Age\": 14.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"2651\", \"Fare\": 11.2417, \"Cabin\": NaN, \"Embarked\": \"C\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are a system that specializes in enriching or transforming given source data with additional attributes according to user requests. Follow the given transformation logic for adding additional features. The task as described by the user: Could you add a field indicating the main explanation for the survival of each passenger?; The transformation logic: 1. Create a new field named \"Survival_Reason\" to indicate the main explanation for the survival of each passenger.\n",
      "   \n",
      "2. Analyze the available data fields like \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", and \"Embarked\" to determine the main explanation for survival.\n",
      "\n",
      "3. Utilize common factors that could influence survival such as being female, being in a higher class, being young, having family members aboard, paying a higher fare, having a cabin, and embarking from certain ports.\n",
      "\n",
      "4. Assign values to the \"Survival_Reason\" field based on the analysis of the mentioned factors for each passenger.\n",
      "\n",
      "5. Take into consideration the possibility of missing data in some fields and handle it appropriately when determining the main explanation for survival.; The output should be formatted as the input sample. The given source data is: {\"titanic\": [{\"PassengerId\": 41, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Ahlin, Mrs. Johan (Johanna Persdotter Larsson)\", \"Sex\": \"female\", \"Age\": 40.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"7546\", \"Fare\": 9.475, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 42, \"Survived\": 0, \"Pclass\": 2, \"Name\": \"Turpin, Mrs. William John Robert (Dorothy Ann Wonnacott)\", \"Sex\": \"female\", \"Age\": 27.0, \"SibSp\": 1, \"Parch\": 0, \"Ticket\": \"11668\", \"Fare\": 21.0, \"Cabin\": NaN, \"Embarked\": \"S\"}, {\"PassengerId\": 43, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Kraeff, Mr. Theodor\", \"Sex\": \"male\", \"Age\": NaN, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"349253\", \"Fare\": 7.8958, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 44, \"Survived\": 1, \"Pclass\": 2, \"Name\": \"Laroche, Miss. Simonne Marie Anne Andree\", \"Sex\": \"female\", \"Age\": 3.0, \"SibSp\": 1, \"Parch\": 2, \"Ticket\": \"SC/Paris 2123\", \"Fare\": 41.5792, \"Cabin\": NaN, \"Embarked\": \"C\"}, {\"PassengerId\": 45, \"Survived\": 1, \"Pclass\": 3, \"Name\": \"Devaney, Miss. Margaret Delia\", \"Sex\": \"female\", \"Age\": 19.0, \"SibSp\": 0, \"Parch\": 0, \"Ticket\": \"330958\", \"Fare\": 7.8792, \"Cabin\": NaN, \"Embarked\": \"Q\"}]}; Please make sure you output a valid JSON format, and don't cut it in the middle. Please make sure the output only contains the dataset structure. Omit any text before or after the JSON structure.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the transformed data: \n",
    " The result of the asynchronous transformation is a dictionary with keys corresponding to dataset names and values as lists of dictionaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert this into a DataFrame for better readability and to leverage DataFrame functionalities for any subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:35.549887Z",
     "start_time": "2024-05-19T12:08:35.526145Z"
    }
   },
   "source": [
    "pd.DataFrame(generated_data['titanic'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "15           16         1       2   \n",
       "16           17         0       3   \n",
       "17           18         1       2   \n",
       "18           19         0       3   \n",
       "19           20         1       3   \n",
       "20           21         0       2   \n",
       "21           22         1       2   \n",
       "22           23         1       3   \n",
       "23           24         1       1   \n",
       "24           25         0       3   \n",
       "25           26         1       3   \n",
       "26           27         0       3   \n",
       "27           28         0       1   \n",
       "28           29         1       3   \n",
       "29           30         0       3   \n",
       "30           31         0       1   \n",
       "31           32         1       1   \n",
       "32           33         1       3   \n",
       "33           34         0       2   \n",
       "34           35         0       1   \n",
       "35           36         0       1   \n",
       "36           37         1       3   \n",
       "37           38         0       3   \n",
       "38           39         0       3   \n",
       "39           40         1       3   \n",
       "40           41         0       3   \n",
       "41           42         0       2   \n",
       "42           43         0       3   \n",
       "43           44         1       2   \n",
       "44           45         1       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)  female  55.0      0   \n",
       "16                               Rice, Master. Eugene    male   2.0      4   \n",
       "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                               Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                        McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                      Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                            Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                     Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                      O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                Todoroff, Mr. Lalio    male   NaN      0   \n",
       "30                           Uruchurtu, Don. Manuel E    male  40.0      0   \n",
       "31     Spencer, Mrs. William Augustus (Marie Eugenie)  female   NaN      1   \n",
       "32                           Glynn, Miss. Mary Agatha  female   NaN      0   \n",
       "33                              Wheadon, Mr. Edward H    male  66.0      0   \n",
       "34                            Meyer, Mr. Edgar Joseph    male  28.0      1   \n",
       "35                     Holverson, Mr. Alexander Oskar    male  42.0      1   \n",
       "36                                   Mamee, Mr. Hanna    male   NaN      0   \n",
       "37                           Cann, Mr. Ernest Charles    male  21.0      0   \n",
       "38                 Vander Planke, Miss. Augusta Maria  female  18.0      2   \n",
       "39                        Nicola-Yarred, Miss. Jamila  female  14.0      1   \n",
       "40     Ahlin, Mrs. Johan (Johanna Persdotter Larsson)  female  40.0      1   \n",
       "41  Turpin, Mrs. William John Robert (Dorothy Ann ...  female  27.0      1   \n",
       "42                                Kraeff, Mr. Theodor    male   NaN      0   \n",
       "43           Laroche, Miss. Simonne Marie Anne Andree  female   3.0      1   \n",
       "44                      Devaney, Miss. Margaret Delia  female  19.0      0   \n",
       "\n",
       "    Parch            Ticket      Fare        Cabin Embarked  \\\n",
       "0       0         A/5 21171    7.2500          NaN        S   \n",
       "1       0          PC 17599   71.2833          C85        C   \n",
       "2       0  STON/O2. 3101282    7.9250          NaN        S   \n",
       "3       0            113803   53.1000         C123        S   \n",
       "4       0            373450    8.0500          NaN        S   \n",
       "5       0            330877    8.4583          NaN        Q   \n",
       "6       0             17463   51.8625          E46        S   \n",
       "7       1            349909   21.0750          NaN        S   \n",
       "8       2            347742   11.1333          NaN        S   \n",
       "9       0            237736   30.0708          NaN        C   \n",
       "10      1           PP 9549   16.7000           G6        S   \n",
       "11      0            113783   26.5500         C103        S   \n",
       "12      0         A/5. 2151    8.0500         None        S   \n",
       "13      5            347082   31.2750         None        S   \n",
       "14      0            350406    7.8542         None        S   \n",
       "15      0            248706   16.0000         None        S   \n",
       "16      1            382652   29.1250         None        Q   \n",
       "17      0            244373   13.0000         None        S   \n",
       "18      0            345763   18.0000         None        S   \n",
       "19      0              2649    7.2250         None        C   \n",
       "20      0            239865   26.0000         None        S   \n",
       "21      0            248698   13.0000          D56        S   \n",
       "22      0            330923    8.0292         None        Q   \n",
       "23      0            113788   35.5000           A6        S   \n",
       "24      1            349909   21.0750         None        S   \n",
       "25      5            347077   31.3875         None        S   \n",
       "26      0              2631    7.2250         None        C   \n",
       "27      2             19950  263.0000  C23 C25 C27        S   \n",
       "28      0            330959    7.8792         None        Q   \n",
       "29      0            349216    7.8958         None        S   \n",
       "30      0          PC 17601   27.7208          NaN        C   \n",
       "31      0          PC 17569  146.5208          B78        C   \n",
       "32      0            335677    7.7500          NaN        Q   \n",
       "33      0        C.A. 24579   10.5000          NaN        S   \n",
       "34      0          PC 17604   82.1708          NaN        C   \n",
       "35      0            113789   52.0000          NaN        S   \n",
       "36      0              2677    7.2292          NaN        C   \n",
       "37      0        A./5. 2152    8.0500          NaN        S   \n",
       "38      0            345764   18.0000          NaN        S   \n",
       "39      0              2651   11.2417          NaN        C   \n",
       "40      0              7546    9.4750          NaN        S   \n",
       "41      0             11668   21.0000          NaN        S   \n",
       "42      0            349253    7.8958          NaN        C   \n",
       "43      2     SC/Paris 2123   41.5792          NaN        C   \n",
       "44      0            330958    7.8792          NaN        Q   \n",
       "\n",
       "                                      Survival_Reason  \n",
       "0   Low chances of survival based on male gender a...  \n",
       "1   High chances of survival based on female gende...  \n",
       "2   High chances of survival based on female gende...  \n",
       "3   High chances of survival based on female gende...  \n",
       "4   Low chances of survival based on male gender a...  \n",
       "5   Low chances of survival based on male gender a...  \n",
       "6   Low chances of survival based on male gender a...  \n",
       "7   Low chances of survival based on male gender a...  \n",
       "8   High chances of survival based on female gende...  \n",
       "9   High chances of survival based on female gende...  \n",
       "10                                             Female  \n",
       "11                                 Female, High Class  \n",
       "12                                               None  \n",
       "13                                               None  \n",
       "14                                             Female  \n",
       "15                                             Female  \n",
       "16                                               None  \n",
       "17                                               None  \n",
       "18                                               None  \n",
       "19                                             Female  \n",
       "20                                     Male passenger  \n",
       "21                                     Male passenger  \n",
       "22                                   Female passenger  \n",
       "23                                     Male passenger  \n",
       "24                Female passenger with family aboard  \n",
       "25                Female passenger with family aboard  \n",
       "26                                     Male passenger  \n",
       "27                  Male passenger with family aboard  \n",
       "28                                   Female passenger  \n",
       "29                                     Male passenger  \n",
       "30  Low chance of survival based on being male, 40...  \n",
       "31  High chance of survival based on being female,...  \n",
       "32  Moderate chance of survival based on being fem...  \n",
       "33  Low chance of survival based on being male, 66...  \n",
       "34  Low chance of survival based on being male, 28...  \n",
       "35  Low chance of survival based on being male, 42...  \n",
       "36  Moderate chance of survival based on being mal...  \n",
       "37  Low chance of survival based on being male, 21...  \n",
       "38  Moderate chance of survival based on being fem...  \n",
       "39  Moderate chance of survival based on being fem...  \n",
       "40                             Being in a lower class  \n",
       "41                             Being in a lower class  \n",
       "42                             Being in a lower class  \n",
       "43  Being female and young, having family members ...  \n",
       "44               Being female, being in a lower class  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survival_Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chances of survival based on male gender a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>High chances of survival based on female gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>High chances of survival based on female gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>High chances of survival based on female gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chances of survival based on male gender a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Low chances of survival based on male gender a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chances of survival based on male gender a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chances of survival based on male gender a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>High chances of survival based on female gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>High chances of survival based on female gende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>Female, High Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Male passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>Male passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Female passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>Male passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Female passenger with family aboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Female passenger with family aboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>Male passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Male passenger with family aboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>Female passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>Male passenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Uruchurtu, Don. Manuel E</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17601</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Low chance of survival based on being male, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spencer, Mrs. William Augustus (Marie Eugenie)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B78</td>\n",
       "      <td>C</td>\n",
       "      <td>High chance of survival based on being female,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Moderate chance of survival based on being fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wheadon, Mr. Edward H</td>\n",
       "      <td>male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 24579</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male, 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mr. Edgar Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Low chance of survival based on being male, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Holverson, Mr. Alexander Oskar</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113789</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male, 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mamee, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Moderate chance of survival based on being mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cann, Mr. Ernest Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A./5. 2152</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Low chance of survival based on being male, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Miss. Augusta Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>345764</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Moderate chance of survival based on being fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicola-Yarred, Miss. Jamila</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Moderate chance of survival based on being fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ahlin, Mrs. Johan (Johanna Persdotter Larsson)</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7546</td>\n",
       "      <td>9.4750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Being in a lower class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Turpin, Mrs. William John Robert (Dorothy Ann ...</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11668</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Being in a lower class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kraeff, Mr. Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349253</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Being in a lower class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Being female and young, having family members ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Devaney, Miss. Margaret Delia</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330958</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Being female, being in a lower class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T12:08:35.553136Z",
     "start_time": "2024-05-19T12:08:35.550894Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 124
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
